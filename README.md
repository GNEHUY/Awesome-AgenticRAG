<div align="center">
  <!-- <p align="center"> -->
  <h1 align="center"><strong>Awesome-AgenticRAG</strong></h1>
</div>

ğŸ”¬ åˆ—ä¸¾ä¸€äº›å…³äºAgenticRAGçš„ç³»åˆ—æ–‡ç« ï¼Œä»¥2025å¹´å¼€å§‹ï¼ŒåŒ…æ‹¬Search-O1ï¼ŒSearch-R1

- [2025.01] [[Search-o1]](https://arxiv.org/abs/2501.05366) Search-o1: Agentic Search-Enhanced Large Reasoning Models å¢å¼ºå…·æœ‰ç±»ä¼¼O1æ¨ç†æ¨¡å¼çš„LRMsçš„è‡ªä¸»æ£€ç´¢èƒ½åŠ›ï¼Œä½¿æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­èƒ½åŠ¨æ€æ£€ç´¢å¤–éƒ¨çŸ¥è¯†ï¼Œä»è€Œæé«˜æ¨ç†çš„å‡†ç¡®æ€§å’Œå¯é æ€§ [![[code]](https://img.shields.io/github/stars/sunnynexus/Search-o1)](https://github.com/sunnynexus/Search-o1)
- [2025.02] [[O1 Embedder]](https://arxiv.org/abs/2502.07555) O1 Embedder: Let Retrievers Think Before Action å·²ç»æœ‰å¾ˆå¤šè®­ç»ƒLLMä½œä¸ºEmbedderçš„å·¥ä½œï¼Œå¦‚ä½•è®©Embedderåœ¨æ£€ç´¢ç›®æ ‡æ–‡æ¡£ä¹‹å‰ç”Ÿæˆå¯¹è¾“å…¥æŸ¥è¯¢æœ‰ç”¨çš„thoughtsï¼Œç±»ä¼¼äºä¸€ä¸ªæ¨ç†çš„è¿‡ç¨‹ï¼Ÿ[![[code]](https://img.shields.io/github/stars/RuiranYan/o1embedder)](https://github.com/RuiranYan/o1embedder)
- [2025.03] [DeepRetrieval](https://arxiv.org/abs/2503.00223) DeepRetrieval: Hacking Real Search Engines and Retrievers with Large Language Models via Reinforcement Learning ä¸å‰é¢åŸºäºç­”æ¡ˆåŒ¹é…åº¦ä½œä¸ºå¥–åŠ±ä¿¡å·ä¸åŒ(å‰é¢ä¸»è¦æ˜¯RAGçš„QAä»»åŠ¡)ï¼Œè¯¥å·¥ä½œä¸»è¦èšç„¦åœ¨æ£€ç´¢ä»»åŠ¡ï¼Œä»¥æ£€ç´¢æŒ‡æ ‡ä½œä¸ºå¥–åŠ±ä¿¡å·ï¼ŒLLMé€šè¿‡æŸ¥è¯¢å¢å¼ºçš„æ–¹å¼ï¼Œè¡¥å……åŸå§‹æŸ¥è¯¢çš„è¯­ä¹‰ï¼Œç„¶åè¿›è¡Œæ£€ç´¢ [![[code]](https://img.shields.io/github/stars/pat-jj/DeepRetrieval)](https://github.com/pat-jj/DeepRetrieval)
- [2025.03] [[Search-R1]](https://arxiv.org/abs/2503.09516) Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning æ”¶åˆ°R1çš„å¯å‘ï¼Œå°†å¼ºåŒ–å­¦ä¹ æ‰©å±•åˆ°RAGåœºæ™¯ï¼Œå°†æœç´¢å¼•æ“å»ºæ¨¡ä¸ºå¼ºåŒ–å­¦ä¹ ç¯å¢ƒçš„ä¸€éƒ¨åˆ†ï¼Œä½¿LLMèƒ½é€šè¿‡è¯•é”™è‡ªä¸»å­¦ä¹ ï¼›ä»…ç”¨æœ€ç»ˆç­”æ¡ˆæ­£ç¡®æ€§ä½œä¸ºå¥–åŠ±ä¿¡å·ï¼Œåˆ›æ–°æ£€ç´¢å†…å®¹æ©ç  [![[code]](https://img.shields.io/github/stars/PeterGriffinJin/Search-R1)](https://github.com/PeterGriffinJin/Search-R1)
- [2025.03] [[R1-Searcher]](https://arxiv.org/abs/2503.05592) R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning ä¸Search-R1ç±»ä¼¼ï¼Œä¸è¿‡é‡‡ç”¨çš„æ˜¯åŸºäºä¸¤é˜¶æ®µRLæ¡†æ¶ï¼Œé€šè¿‡è‡ªä¸»è°ƒç”¨å¤–éƒ¨æœç´¢å·¥å…·å¢å¼ºLLMçš„å›ç­”èƒ½åŠ›ï¼Œæ— è¿‡ç¨‹å¥–åŠ±æˆ–è’¸é¦ã€‚ä»…ä¾èµ–æœ€ç»ˆå¥–åŠ±ã€‚ [![[code]](https://img.shields.io/github/stars/RUCAIBox/R1-Searcher)](https://github.com/RUCAIBox/R1-Searcher)
- [2025.03] [[ReSearch]](https://arxiv.org/abs/2503.19470) ReSearch: Learning to Reason with Search for LLMs via Reinforcement Learning åŸºæœ¬å’ŒSearch-R1ä¸€æ ·ï¼Œä¸åŒç‚¹åœ¨äºè€ƒè™‘äº†æ ¼å¼å¥–åŠ±ï¼ŒåŒæ—¶ç”¨çš„æ˜¯F1 score [![[code]](https://img.shields.io/github/stars/Agent-RL/ReSearch)](https://github.com/Agent-RL/ReSearch)
- [2025.03] [[ReAgent]](https://arxiv.org/abs/2503.06951) ReAgent: Reversible Multi-Agent Reasoning for  Knowledge-Enhanced Multi-Hop QA é€šè¿‡å¼•å…¥å¤šæ™ºèƒ½ä½“å¯é€†å›æº¯æ¨ç†æœºåˆ¶ï¼Œè§£å†³äº†å¤šè·³é—®ç­”ä¸­é”™è¯¯ç§¯ç´¯å’Œä¸å¯çº æ­£çš„é—®é¢˜ã€‚ [![[code]](https://img.shields.io/github/stars/astridesa/ReAgent)](https://github.com/astridesa/ReAgent)
- [2025.04] [[DeepResearcher]](https://arxiv.org/abs/2504.03160) DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-World Environments æ˜¯ç°æœ‰æœç´¢ä»£ç†åœ¨å®é™…ç¯å¢ƒä¸­æ‰©å±•å›°éš¾ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ åœ¨çœŸå®ç¯å¢ƒä¸­æ‰©å±•æ·±åº¦ç ”ç©¶èƒ½åŠ›ï¼Œç¼ºå°‘åœ¨çœŸå®ç½‘ç»œç¯å¢ƒä¸­ï¼Œåº”å¯¹ç¯å¢ƒåŠ¨æ€æ€§ï¼Œä¸å¯é¢„æµ‹æ€§ï¼Œå™ªå£°ã€æœç´¢ç½‘é¡µè´¨é‡å·®å¼‚å’Œå†…å®¹æ ¼å¼é—®é¢˜çš„å¼ºå¤§Agentæ¡†æ¶ï¼Œä¸ä»…æœ‰Searchè¿˜æœ‰Browse [![[code]](https://img.shields.io/github/stars/GAIR-NLP/DeepResearcher)](https://github.com/GAIR-NLP/DeepResearcher)
- [2025.05] [[AutoRefine]](https://arxiv.org/abs/2505.11277) Search and Refine During Think: Facilitating Knowledge Refinement for Improved Retrieval-Augmented Reasoning Search-R1æ£€ç´¢åˆ°çš„æ–‡æ¡£å¾€å¾€åŒ…å«æ— å…³å†…å®¹ï¼Œå¯èƒ½å½±å“åˆ°æ¨¡å‹æœ‰æ•ˆåˆ©ç”¨æ–°çš„çŸ¥è¯†ã€‚å¯ä»¥è€ƒè™‘è¾¹æ£€ç´¢ï¼Œè¾¹ç²¾ç‚¼çš„æ–¹å¼ï¼Œä½¿æ¨¡å‹åœ¨æ£€ç´¢è¿‡ç¨‹ä¸­è‡ªæˆ‘è¿›åŒ–ã€‚åŒæ—¶ç²¾ç‚¼è¿‡ç¨‹æä¾›å¥–åŠ±ï¼Œé¿å…ä»…ç»“æœå¥–åŠ± [![[code]](https://img.shields.io/github/stars/syr-cn/AutoRefine)](https://github.com/syr-cn/AutoRefine)
- [2025.05] [[IKEA]](https://arxiv.org/abs/2505.07596) IKEA: Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent è§£å†³ç°æœ‰æœç´¢ä»£ç†è¿‡åº¦ä¾èµ–å¤–éƒ¨æœç´¢ã€æœªå……åˆ†åˆ©ç”¨å†…éƒ¨çŸ¥è¯†çš„é—®é¢˜ï¼Œæå‡ºå¼ºåŒ–å­¦ä¹ çš„å†…å¤–éƒ¨çŸ¥è¯†ååŒæ¨ç†ä»£ç†ï¼Œè¯†åˆ«çŸ¥è¯†è¾¹ç•Œï¼Œä¼˜å…ˆä½¿ç”¨å†…éƒ¨çŸ¥è¯†ï¼Œå‡å°‘å†—ä½™æ£€ç´¢å’ŒçŸ¥è¯†å†²çª [![[code]](https://img.shields.io/github/stars/hzy312/knowledge-r1)](https://github.com/hzy312/knowledge-r1)
- [2025.05] [[ZeroSearch]](https://arxiv.org/abs/2505.04588) ZeroSearch: Incentivize the Search Capability of LLMs without Searching è§£å†³RLè®­ç»ƒæœç´¢ä»£ç†æ—¶é¢ä¸´çš„æ–‡æ¡£è´¨é‡ä¸å¯æ§å’ŒAPIæˆæœ¬é«˜æ˜‚ä¸¤å¤§æŒ‘æˆ˜ï¼Œæ— éœ€çœŸå®æœç´¢ï¼Œç›´æ¥ç”¨LLMæ¨¡æ‹Ÿæœç´¢å¼•æ“ï¼Œå¼•å…¥è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œåœ¨é™ä½88%æˆæœ¬çš„åŒæ—¶æ€§èƒ½è¶…è¿‡ä¾èµ–çœŸå®æœç´¢çš„æ–¹æ³• [![[code]](https://img.shields.io/github/stars/Alibaba-NLP/ZeroSearch)](https://github.com/Alibaba-NLP/ZeroSearch)
- [2025.05] [[s3]](https://arxiv.org/abs/2505.14146) s3: You Don't Need That Much Data to Train a Search Agent via RL è§£å†³ç°æœ‰æ–¹æ³•è¦ä¹ˆä¼˜åŒ–æ£€ç´¢æŒ‡æ ‡å¿½ç•¥ä¸‹æ¸¸æ•ˆç”¨ï¼Œè¦ä¹ˆç«¯åˆ°ç«¯è®­ç»ƒå¯¼è‡´æœç´¢ä¸ç”Ÿæˆçº ç¼ çš„é—®é¢˜ï¼Œæå‡ºè½»é‡çº§æ¡†æ¶è§£è€¦æœç´¢å™¨å’Œç”Ÿæˆå™¨ï¼Œä»…ç”¨2.4kè®­ç»ƒæ ·æœ¬å®ç°å¼ºå¤§æ€§èƒ½ï¼Œæå‡ºGain Beyond RAGå¥–åŠ± [![[code]](https://img.shields.io/github/stars/pat-jj/s3)](https://github.com/pat-jj/s3)
- [2025.05] [[StepSearch]](https://arxiv.org/abs/2505.15107) StepSearch: Igniting LLMs Search Ability via Step-Wise Proximal Policy Optimization ç›®å‰Search-R1ç­‰ç°æœ‰æ–¹æ³•å› ä¾èµ–ç¨€ç–å…¨å±€å¥–åŠ±è€Œç¼ºä¹å¯¹ä¸­é—´æœç´¢è¿‡ç¨‹ç»†ç²’åº¦ç›‘ç£çš„é—®é¢˜ï¼Œé€šè¿‡å¼•å…¥åŸºäºä¿¡æ¯å¢ç›Šå’Œå†—ä½™æƒ©ç½šçš„tokençº§åˆ«æ­¥éª¤å¥–åŠ±æœºåˆ¶ï¼ˆStePPOï¼‰ï¼Œè§£å†³äº†å…¶åœ¨å¤æ‚å¤šè·³é—®ç­”ä¸­ç¼ºä¹ä¸­é—´æŸ¥è¯¢å’Œå¤šæ­¥æ£€ç´¢ç»†ç²’åº¦ç›‘ç£çš„é—®é¢˜ã€‚éœ€è¦åšæ•°æ®å¢å¼ºå¾—åˆ°Goldenè½¨è¿¹ [![[code]](https://img.shields.io/github/stars/Zillwang/StepSearch)](https://github.com/Zillwang/StepSearch)
- [2025.05] [[R1-Searcher++]](https://arxiv.org/abs/2505.17005) R1-Searcher++: Incentivizing the Dynamic Knowledge Acquisition of LLMs via Reinforcement Learning ä½œä¸ºR1-Searcherçš„å¢å¼ºç‰ˆï¼Œè§£å†³å¦‚ä½•æ›´å¥½åœ°åˆ©ç”¨å†…éƒ¨å’Œå¤–éƒ¨çŸ¥è¯†çš„é—®é¢˜ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µç­–ç•¥ï¼Œå¼•å…¥å†…éƒ¨çŸ¥è¯†åˆ©ç”¨å¥–åŠ±æœºåˆ¶å’Œè®°å¿†æœºåˆ¶ï¼Œå®ç°åŠ¨æ€çŸ¥è¯†è·å– [![[code]](https://img.shields.io/github/stars/RUCAIBox/R1-Searcher-plus)](https://github.com/RUCAIBox/R1-Searcher-plus)
- [2025.05] [[Search Wisely Î²-GRPO]](https://arxiv.org/abs/2505.17281) Search Wisely: Mitigating Sub-optimal Agentic Searches By Reducing Uncertainty è§£å†³ä»£ç†æœç´¢ä¸­å­˜åœ¨çš„ä¸ç¡®å®šæ€§å¯¼è‡´æ¬¡ä¼˜æœç´¢è¡Œä¸ºï¼ˆæœç´¢ä¸è¶³orå†—ä½™æœç´¢ï¼‰çš„é—®é¢˜ï¼Œé€šè¿‡å‡å°‘ä¸ç¡®å®šæ€§æ¥ç¼“è§£æ¬¡ä¼˜çš„ä»£ç†æœç´¢ï¼Œæé«˜æœç´¢æ•ˆç‡å’Œè´¨é‡ [![[code]](https://img.shields.io/github/stars/mianzhang/Search-R1)](https://github.com/mianzhang/Search-R1)
- [2025.05] [[LeTS]](https://arxiv.org/abs/2505.17447) LeTS: Learning to Think-and-Search via Process-and-Outcome Reward Hybridization è§£å†³äº†Search-R1/ReSearchç­‰ç»“æœç›‘ç£RLæ–¹æ³•å› å¿½ç•¥ä¸­é—´æ­¥éª¤è€Œå¯¼è‡´çš„å†—ä½™æœç´¢ä¸æ— å…³æœç´¢é—®é¢˜ï¼Œé€šè¿‡è®¾è®¡åŸºäºè§„åˆ™çš„è¿‡ç¨‹çº§å¥–åŠ±æ¨¡å—ï¼ˆåŒ…æ‹¬ æƒ©ç½šåŒä¸€è½¨è¿¹å†…é‡å¤æ£€ç´¢ç›¸åŒæ–‡æ¡£çš„è¡Œä¸º å’Œ åˆ©ç”¨ç»„å†…ä¼˜ç§€è½¨è¿¹æŒ‡å¯¼å¼±è½¨è¿¹ï¼Œè§£å†³æ— å…³æœç´¢é—®é¢˜ï¼‰å¹¶ç”¨è¿‡ç¨‹å¥–åŠ±åŠ¨æ€è°ƒæ•´ç»“æœå¥–åŠ±çš„ä¼˜åŠ¿å€¼å®ç°è¿‡ç¨‹-ç»“æœå¥–åŠ±æ··åˆ [![[code]](https://img.shields.io/github/stars/Cheungki/LeTS)](https://github.com/Cheungki/LeTS)
- [2025.05] [[EvolveSearch]](https://arxiv.org/abs/2505.22501) EvolveSearch: An Iterative Self-Evolving Search Agent è§£å†³å½“å‰æœç´¢ä»£ç†éœ€è¦å¤–éƒ¨äººå·¥æ ‡æ³¨æ¨ç†è½¨è¿¹çš„é—®é¢˜ï¼Œæå‡ºè¿­ä»£è‡ªè¿›åŒ–æ¡†æ¶ï¼ŒååŒç»“åˆRLä¸SFTï¼Œæ— éœ€å¤–éƒ¨äººå·¥æ ‡æ³¨å³å¯æå‡ç½‘ç»œæœç´¢èƒ½åŠ›ï¼Œå®ç°è‡ªæˆ‘è¿›åŒ–
- [2025.06] [[R-Search]](https://arxiv.org/abs/2506.04185) R-Search: Empowering LLM Reasoning with Search via Multi-Reward Reinforcement Learning é€šè¿‡å¼•å…¥å¤šé˜¶æ®µæ··åˆå¥–åŠ±æœºåˆ¶ï¼ˆç­”æ¡ˆè´¨é‡ã€è·¨æ¨¡å‹è¯æ®è´¨é‡ã€æ ¼å¼æ­£ç¡®æ€§ï¼‰å’Œè¯æ®æ•´åˆæ¨¡å—ï¼Œè§£å†³äº†Search-R1ä¸­æ£€ç´¢æ—¶æœºä¸çœŸå®éœ€æ±‚ä¸å¯¹é½ã€æ¨ç†-æœç´¢äº¤äº’æ·±åº¦å—é™çš„é—®é¢˜ï¼Œä½¿LLMèƒ½å¤ŸåŠ¨æ€å†³å®šä½•æ—¶æ£€ç´¢å¹¶ä»å…¨å±€è§†è§’æç‚¼å…³é”®è¯æ®ï¼Œä»è€Œä¼˜åŒ–æ•´ä¸ªæ¨ç†-æœç´¢äº¤äº’è½¨è¿¹ [![[code]](https://img.shields.io/github/stars/QingFei1/R-Search)](https://github.com/QingFei1/R-Search)
- [2025.08] [[Self-Search RL]](https://arxiv.org/abs/2508.10874) SSRL: Self-Search Reinforcement Learning ç ”ç©¶LLMä½œä¸ºRLä»»åŠ¡æ¨¡æ‹Ÿå™¨çš„æ½œåŠ›ï¼Œè®­ç»ƒLLMç›´æ¥ä½œä¸ºæœç´¢å¼•æ“ï¼Œå‡å°‘å¯¹å¤–éƒ¨æœç´¢å¼•æ“çš„æ˜‚è´µäº¤äº’ä¾èµ–ï¼Œé€šè¿‡ç»“æ„åŒ–æç¤ºå’Œé‡å¤é‡‡æ ·é‡åŒ–LLMçš„å†…åœ¨æœç´¢èƒ½åŠ›ï¼Œå¢å¼ºè‡ªæˆ‘æœç´¢èƒ½åŠ› [![[code]](https://img.shields.io/github/stars/TsinghuaC3I/SSRL)](https://github.com/TsinghuaC3I/SSRL)
- [2025.08] [[ASearcher]](https://arxiv.org/abs/2508.07976) Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL è§£å†³é•¿è§†é‡æœç´¢ä»»åŠ¡çš„æŒ‘æˆ˜ï¼Œé€šè¿‡å¤§è§„æ¨¡å¼‚æ­¥å¼ºåŒ–å­¦ä¹ è§£é”é•¿è§†é‡ä»£ç†æœç´¢èƒ½åŠ›ï¼Œæ”¯æŒè¶…è¿‡åè½®ä»¥ä¸Šçš„å¤æ‚æœç´¢äº¤äº’ [![[code]](https://img.shields.io/github/stars/inclusionAI/ASearcher)](https://github.com/inclusionAI/ASearcher)
- [2025.08] [[Atom-Searcher]](https://arxiv.org/abs/2508.12800) Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward æ·±åº¦ç ”ç©¶ä¾èµ–ç»“æœå¥–åŠ± RLï¼Œå­˜åœ¨æ¢¯åº¦å†²çªä¸å¥–åŠ±ç¨€ç–ï¼Œè®­ç»ƒä½æ•ˆä¸”éš¾æ”¶æ•›ã€‚æå‡ºâ€œåŸå­æ€ç»´â€èŒƒå¼ï¼ŒæŠŠæ¨ç†æ‹†æˆç»†ç²’åº¦åŠŸèƒ½å•å…ƒï¼Œå¹¶è®¾è®¡åŸå­æ€ç»´å¥–åŠ± ATR å¯¹å…¶é€æ®µæ‰“åˆ†ï¼›å†ç”¨è¯¾ç¨‹å¼èšåˆç­–ç•¥å…ˆé‡è¿‡ç¨‹ ATRã€åé‡ç»“æœå¥–åŠ±ï¼Œå¹³æ»‘ä¼˜åŒ–è·¯å¾„ã€‚Atom-Searcher æ¡†æ¶ = åŸå­æ€ç»´åˆ†è§£ + ATR ç»†ç²’åº¦å¼•å¯¼ + è¯¾ç¨‹å¼æ··åˆå¥–åŠ±ï¼Œæ— éœ€é¢å¤–æ ‡æ³¨å³å¯åœ¨ä¸ƒé¡¹åŸºå‡†ä¸Šç¨³å®šè¶…è¶Š SOTAï¼Œæ¨ç†æ›´å¯è§£é‡Šã€æµ‹è¯•ç®—åŠ›å¯ä¼¸ç¼©ã€‚[![[code]](https://img.shields.io/github/stars/antgroup/Research-Venus)](https://github.com/antgroup/Research-Venus)
- [2025.09] [[EviNote-RAG]](https://arxiv.org/abs/2509.00877) EviNote-RAG: Enhancing RAG Models via Answer-Supportive Evidence Notes é’ˆå¯¹ RAG ä¿¡å·å™ªå£°ä½ã€å¤šè·³è¯¯å·®ç´¯ç§¯ä¸¤å¤§ç—›ç‚¹ï¼Œæå‡ºâ€œæ£€ç´¢â†’ç¬”è®°â†’å›ç­”â€æ–°æµç¨‹ï¼šå…ˆè®©æ¨¡å‹æŠŠåŸå§‹æ–‡æ¡£è’¸é¦æˆâ€œæ”¯æŒè¯æ®ç¬”è®°â€ï¼ˆSENï¼‰ï¼Œæ˜¾å¼æ ‡è®°å…³é”®ä¸ä¸ç¡®å®šä¿¡æ¯ï¼Œå†ç”¨åŸºäºè•´æ¶µçš„ Evidence Quality Reward ä¿è¯ç¬”è®°è¶³ä»¥æ¨å‡ºç­”æ¡ˆ [![[code]](https://img.shields.io/github/stars/Da1yuqin/EviNoteRAG)](https://github.com/Da1yuqin/EviNoteRAG)
- [2025.09] [[AceSearcher]](https://arxiv.org/abs/2509.24193) AceSearcher: Bootstrapping Reasoning and Search for LLMs via Reinforced Self-Play æ£€ç´¢å¢å¼º LLM å¤šè·³æ£€ç´¢å¼±ã€æ¨ç†å·®ï¼Œäºæ˜¯è®©åŒä¸€æ¨¡å‹â€œå·¦å³äº’æâ€ï¼šè‡ªæ¼”åˆ†è§£è€…+è§£é¢˜è€…ï¼Œç”¨ç›‘ç£å¾®è°ƒæ··åˆæœç´¢æ¨ç†ä»»åŠ¡åï¼Œå†ç›´æ¥ç”¨æœ€ç»ˆç­”æ¡ˆå‡†ç¡®ç‡åšå¼ºåŒ–å­¦ä¹ ï¼Œæ— éœ€ä¸­é—´æ ‡æ³¨ï¼Œ10 æ•°æ®é›†å¹³å‡ EM æå‡ 7.6%ï¼Œ32B ç‰ˆä»…ç”¨ DeepSeek-V3 5% å‚æ•°å°±åœ¨é‡‘èæ–‡æ¡£æ¨ç†ä¸Šæ‰“å¹³ï¼Œ1.5/8B ç‰ˆä¹Ÿå¸¸è·‘èµ¢å‚æ•°é‡å¤§ 9 å€çš„ç°æœ‰æ¨¡å‹ã€‚[![[code]](https://img.shields.io/github/stars/ritaranx/AceSearcher)](https://github.com/ritaranx/AceSearcher)
- [2025.10] [[DeSA]](https://arxiv.org/abs/2510.04695) Beyond Outcome Reward: Decoupling Search and Answering Improves LLM Agents ç›®å‰Search-R1ä¸»è¦ä¾èµ–åŸºäºç»“æœçš„å¥–åŠ±ï¼Œè¿™éšå«äº†ä¸€ä¸ªå…³é”®å‡è®¾ï¼šä¼˜åŒ–æœ€ç»ˆç­”æ¡ˆä¼šè‡ªåŠ¨æ•™ä¼šæ™ºèƒ½ä½“è¿›è¡Œæœ‰æ•ˆæœç´¢ã€‚ä½œè€…è´¨ç–‘è¿™ä¸€å‡è®¾ï¼ŒæŒ‡å‡ºç»“æœå¥–åŠ±å­˜åœ¨ä»¥ä¸‹æ ¹æœ¬ç¼ºé™·ï¼šä¿¡ç”¨åˆ†é…é—®é¢˜ï¼šç»“æœå¥–åŠ±æä¾›çš„æ˜¯ç¨€ç–ã€å»¶è¿Ÿçš„åé¦ˆï¼Œæ— æ³•æœ‰æ•ˆæŒ‡å¯¼ä¸­é—´çš„æœç´¢è¡Œä¸º è¡Œä¸º-ç»“æœè„±èŠ‚ï¼šæ²¡æœ‰è¯æ®è¡¨æ˜å¥½çš„ç»“æœå¿…ç„¶æ¥è‡ªäºæœ‰æ•ˆçš„æœç´¢è¿‡ç¨‹ã€‚å¯¼è‡´ä¸æœç´¢ï¼Œé‡å¤æœç´¢ï¼Œæ— æ•ˆæœç´¢ã€‚ [![[code]](https://img.shields.io/github/stars/yiding-w/DeSA)](https://github.com/yiding-w/DeSA)
- [2025.10] [[DecEx-RAG]](https://arxiv.org/abs/2510.05691) DecEx-RAG: Boosting Agentic Retrieval-Augmented Generation with Decision and Execution Optimization via Process Supervision å°†RAGå»ºæ¨¡ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼Œæ˜¾å¼è§£è€¦å†³ç­–ï¼ˆç»ˆæ­¢/æ£€ç´¢ï¼‰ä¸æ‰§è¡Œï¼ˆå†…å®¹è´¨é‡ï¼‰ä¸¤é˜¶æ®µï¼Œé€šè¿‡æœç´¢æ ‘æ„å»ºè¿‡ç¨‹ç›‘ç£æ•°æ®ï¼Œå¹¶åˆ©ç”¨å¤šè½®rolloutçš„èšåˆå¥–åŠ±åŠ¨æ€å‰ªæå†—ä½™åˆ†æ”¯ï¼Œå°†æœç´¢å¤æ‚åº¦ä»æŒ‡æ•°é™ä¸ºçº¿æ€§ã€‚é‡‡ç”¨SFT+DPOä¸¤é˜¶æ®µè®­ç»ƒå­¦ä¹ æœ€ä¼˜å†³ç­–ä¸æ‰§è¡Œç­–ç•¥ [![[code]](https://img.shields.io/github/stars/sdsxdxl/DecEx-RAG)](https://github.com/sdsxdxl/DecEx-RAG)
- [2025.10] [[HiPRAG]](https://arxiv.org/abs/2510.07794) HiPRAG: Hierarchical Process Rewards for Efficient Agentic Retrieval Augmented Generation é€šè¿‡åˆ†å±‚è¿‡ç¨‹å¥–åŠ±ä¼˜åŒ–RAGæ™ºèƒ½ä½“æœç´¢å†³ç­–ï¼Œå°†æ¨ç†è½¨è¿¹åˆ†è§£ä¸ºå¯è§£ææ­¥éª¤å¹¶å®æ—¶æ£€æµ‹å†—ä½™/ç¼ºå¤±æœç´¢ Î²-GRPOç»­ä½œ [![[code]](https://img.shields.io/github/stars/qualidea1217/HiPRAG)](https://github.com/qualidea1217/HiPRAG)
- [2025.10] [[QAgent]](https://arxiv.org/abs/2510.08383) QAgent: A modular Search Agent with Interactive Query Understanding è§£å†³ä¼ ç»ŸRAGéš¾ä»¥ç†è§£å¤æ‚æŸ¥è¯¢ã€RLè®­ç»ƒæœç´¢ä»£ç†æ³›åŒ–å’Œéƒ¨ç½²å›°éš¾çš„é—®é¢˜ï¼Œæå‡ºæ¨¡å—åŒ–æœç´¢ä»£ç†æ¡†æ¶ï¼Œé€šè¿‡äº¤äº’å¼æ¨ç†å’Œæ£€ç´¢ä¼˜åŒ–æŸ¥è¯¢ç†è§£ï¼Œå³æ’å³ç”¨äºå¤æ‚ç³»ç»Ÿ [![[code]](https://img.shields.io/github/stars/LivingFutureLab/QAgent)](https://github.com/LivingFutureLab/QAgent)
- [2025.10] [[InfoFlow]](https://arxiv.org/abs/2510.26575) InfoFlow: Reinforcing Search Agent via Reward Density Optimization è§£å†³æ·±åº¦æœç´¢åœºæ™¯ä¸­å¥–åŠ±å¯†åº¦ä½ã€æ¢ç´¢æˆæœ¬é«˜çš„é—®é¢˜ï¼Œæå‡ºå¥–åŠ±å¯†åº¦ä¼˜åŒ–æ¡†æ¶ï¼Œé€šè¿‡å­é—®é¢˜åˆ†è§£ã€å¤±è´¥å¼•å¯¼æç¤ºå’ŒåŒä»£ç†ç²¾ç‚¼ä¸‰æ–¹é¢æé«˜å¥–åŠ±å¯†åº¦å’Œè®­ç»ƒæ•ˆç‡
- [2025.10] [[Search Self-play]](https://arxiv.org/abs/2510.18821) Search Self-play: Pushing the Frontier of Agent Capability without Supervision è§£å†³æ— ç›‘ç£æƒ…å†µä¸‹å¦‚ä½•æå‡ä»£ç†èƒ½åŠ›çš„é—®é¢˜ï¼Œé€šè¿‡æœç´¢è‡ªæˆ‘åšå¼ˆå¼ºåŒ–å­¦ä¹ ï¼Œè®©LLMäº¤æ›¿æé—®å’Œè§£å†³æŒç»­è®­ç»ƒè‡ªæˆ‘è¿›åŒ–ï¼Œæ— éœ€ç›‘ç£å³å¯æ¨åŠ¨ä»£ç†èƒ½åŠ›è¾¹ç•Œï¼Œè§£å†³å½“å‰è®­ç»ƒAgentçš„RLæ–¹æ³•å¯¹æ•°æ®çš„ä¾èµ–é—®é¢˜ [![[code]](https://img.shields.io/github/stars/Alibaba-Quark/SSP)](https://github.com/Alibaba-Quark/SSP)
- [2025.10] [[E-GRPO]](https://arxiv.org/abs/2510.24694) Repurposing Synthetic Data for Fine-grained Search Agent Supervision è§£å†³GRPOæ–¹æ³•ç¼ºä¹ç»†ç²’åº¦ç›‘ç£ä¿¡å·çš„é—®é¢˜ï¼Œæå‡ºE-GRPOæ¡†æ¶ï¼Œåˆ©ç”¨åˆæˆæ•°æ®ä¸­çš„å®ä½“ä¿¡æ¯ä½œä¸ºç»†ç²’åº¦å¥–åŠ±ï¼Œè§£å†³"è¿‘å¤±"é—®é¢˜ï¼Œæå‡å¤æ‚æœç´¢ä»»åŠ¡æ€§èƒ½
- [2025.10] [[GlobalRAG]](https://arxiv.org/abs/2510.20548) GlobalRAG: Enhancing Global Reasoning in Multi-hop Question Answering via Reinforcement Learning è§£å†³å¤šè·³QAä¸­ç¼ºä¹å…¨å±€è§„åˆ’å’Œä¸å¿ å®æ‰§è¡Œçš„é—®é¢˜ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ å¢å¼ºå…¨å±€æ¨ç†ï¼Œåˆ†è§£é—®é¢˜ä¸ºå­ç›®æ ‡ï¼Œåè°ƒæ£€ç´¢ä¸æ¨ç†ï¼Œä»…ä½¿ç”¨8kè®­ç»ƒæ•°æ®å°±å®ç°æ˜¾è‘—æ€§èƒ½æå‡ã€‚éœ€è¦åšæ•°æ®å¢å¼ºå¾—åˆ°Goldenè½¨è¿¹ [![[code]](https://img.shields.io/github/stars/CarnegieBin/GlobalRAG)](https://github.com/CarnegieBin/GlobalRAG)
- [2025.10] [[Interact-RAG]](https://arxiv.org/abs/2510.27566) Interact-RAG: Reason and Interact with the Corpus, Beyond Black-Box Retrieval ç°æœ‰Agentic RAGæ–¹æ³•å°†æ£€ç´¢è¿‡ç¨‹è§†ä¸ºé»‘ç›’ï¼Œæ™ºèƒ½ä½“åªèƒ½è¢«åŠ¨æŸ¥è¯¢ï¼Œé™åˆ¶äº†å¤æ‚ä»»åŠ¡çš„ä¿¡æ¯æ¢ç´¢èƒ½åŠ›ã€‚Interact-RAGé€šè¿‡è¯­æ–™åº“äº¤äº’å¼•æ“èµ‹äºˆæ™ºèƒ½ä½“ç»†ç²’åº¦æ£€ç´¢æ§åˆ¶æƒï¼šå¤šé¢æ£€ç´¢ï¼ˆè¯­ä¹‰/ç²¾ç¡®æœç´¢ã€åŠ æƒèåˆï¼‰é”šå®šåŒ¹é…ï¼ˆå®ä½“åŒ¹é…èšç„¦å…³é”®ä¿¡æ¯ï¼‰ä¸Šä¸‹æ–‡å¡‘é€ ï¼ˆåŠ¨æ€åŒ…å«/æ’é™¤æ–‡æ¡£ã€è°ƒæ•´æ£€ç´¢è§„æ¨¡ï¼‰é…åˆæ¨ç†å¢å¼ºå·¥ä½œæµï¼ˆå…¨å±€è§„åˆ’å™¨â†’è‡ªé€‚åº”æ¨ç†å™¨â†’æ‰§è¡Œå™¨ï¼‰å®ç°é›¶æ ·æœ¬æ‰§è¡Œå’Œè½¨è¿¹åˆæˆï¼Œå†é€šè¿‡SFT+RLä¸¤é˜¶æ®µè®­ç»ƒï¼ˆGRPOç®—æ³•ï¼‰å†…åŒ–ç­–ç•¥
- [2025.10] [[MARAG-R1]](https://arxiv.org/abs/2510.27569) MARAG-R1: Beyond Single Retriever via Reinforcement-Learned Multi-Tool Agentic Retrieval ç°æœ‰RAGç³»ç»Ÿä¾èµ–å•ä¸€æ£€ç´¢å™¨å’Œå›ºå®šçš„top-ké€‰æ‹©ç­–ç•¥ï¼Œè¿™å¯¼è‡´ï¼šåªèƒ½è®¿é—®è¯­æ–™åº“çš„ç‹­çª„é™æ€å­é›†ï¼›æ— æ³•è·å–ä»»åŠ¡æ‰€éœ€çš„å…¨é¢å¤–éƒ¨ä¿¡æ¯ï¼›åœ¨éœ€è¦è¯­æ–™åº“çº§æ¨ç†å’Œè·¨æ–‡æ¡£ç»¼åˆçš„ä»»åŠ¡ä¸Šæˆä¸ºä¸»è¦ç“¶é¢ˆã€‚å¤šå·¥å…·æ¶æ„ï¼šä¸ºLLMé…å¤‡å››ç§äº’è¡¥çš„æ£€ç´¢å·¥å…·ï¼šè¯­ä¹‰æœç´¢ï¼ˆå¹¿åº¦æ¢ç´¢ï¼‰å…³é”®è¯æœç´¢ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰æ–‡æ¡£è¿‡æ»¤ï¼ˆåŸºäºçº¦æŸé€‰æ‹©ï¼‰èšåˆå·¥å…·ï¼ˆç»Ÿè®¡ç»¼åˆï¼‰ä¸¤é˜¶æ®µè®­ç»ƒï¼šSFT+RL å¤åˆå¥–åŠ±è®¾è®¡ï¼šç­”æ¡ˆå¥–åŠ± + æ–‡æ¡£è¦†ç›–ç‡å¥–åŠ± + å·¥å…·æ¢ç´¢å¥–åŠ±ï¼šå¹³è¡¡æ¢ç´¢æ•ˆç‡ï¼Œé¿å…å†—ä½™è°ƒç”¨
- [2025.11] [[TeaRAG]](https://arxiv.org/abs/2511.05385) TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework ç°æœ‰Agentic RAGæ–¹æ³•å› è¿‡åº¦å…³æ³¨ç­”æ¡ˆå‡†ç¡®æ€§è€Œå¿½è§†tokenå¼€é”€ï¼Œå¯¼è‡´æ¨¡å‹è¿‡åº¦æ€è€ƒå’Œå†—ä½™æ£€ç´¢ï¼Œä¸”è®­ç»ƒæ•ˆç‡ä½ä¸‹ã€‚TeaRAGé€šè¿‡ä¸¤ä¸ªå±‚é¢æå‡tokenæ•ˆç‡ï¼š1) æ£€ç´¢å‹ç¼©ï¼šæ„å»ºçŸ¥è¯†å…³è”å›¾èåˆè¯­ä¹‰æ£€ç´¢ä¸ä¸‰å…ƒç»„å›¾æ£€ç´¢ï¼Œç”¨Personalized PageRankç­›é€‰å…³é”®ä¿¡æ¯ï¼Œä»¥é«˜å¯†åº¦çŸ¥è¯†ä¸‰å…ƒç»„æ›¿ä»£å†—ä½™æ–‡æœ¬å—ï¼›2) æ¨ç†å‹ç¼©ï¼šæå‡ºè¿­ä»£å¼è¿‡ç¨‹æ„ŸçŸ¥DPOï¼ˆIP-DPOï¼‰ï¼Œè®¾è®¡åŸºäºçŸ¥è¯†åŒ¹é…çš„è¿‡ç¨‹å¥–åŠ±å‡½æ•°è¯„ä¼°æ¯æ­¥çš„çŸ¥è¯†å……åˆ†æ€§å¹¶æƒ©ç½šå¤šä½™æ­¥éª¤ï¼Œé€šè¿‡è¿­ä»£ä¼˜åŒ–ç”Ÿæˆæ›´ç®€æ´çš„æ¨ç†è·¯å¾„ã€‚[![[code]](https://img.shields.io/github/stars/Applied-Machine-Learning-Lab/TeaRAG)](https://github.com/Applied-Machine-Learning-Lab/TeaRAG)
- [2025.11] [[IterResearch]](https://arxiv.org/abs/2511.07327) IterResearch: Rethinking Long-Horizon Agents via Markovian State Reconstruction é€šè¿‡é©¬å°”å¯å¤«çŠ¶æ€é‡å»ºæœºåˆ¶ï¼ˆç”¨æ¼”è¿›æŠ¥å‘Šæ›¿ä»£å®Œæ•´å†å²ä¸Šä¸‹æ–‡ï¼‰è§£å†³äº†å•ä¸Šä¸‹æ–‡èŒƒå¼çš„ä¸Šä¸‹æ–‡çª’æ¯ä¸å™ªå£°æ±¡æŸ“é—®é¢˜ï¼Œä½¿æ™ºèƒ½ä½“åœ¨ä»»æ„æ¢ç´¢æ·±åº¦ï¼ˆå®éªŒéªŒè¯è‡³ 2048 è½®ï¼‰ä¿æŒæ’å®šæ¨ç†èƒ½åŠ›ã€‚æå‡ºEAPOï¼ˆæ•ˆç‡æ„ŸçŸ¥ç­–ç•¥ä¼˜åŒ–ï¼‰â€”â€”å¼•å…¥å‡ ä½•æŠ˜æ‰£å¥–åŠ±æ¿€åŠ±é«˜æ•ˆæ¢ç´¢ï¼Œé…åˆè‡ªé€‚åº”ä¸‹é‡‡æ ·å®ç°ç¨³å®šåˆ†å¸ƒå¼è®­ç»ƒã€‚
- [2025.11] [[Bi-RAR]](https://arxiv.org/abs/2511.09109) Thinking Forward and Backward: Multi-Objective Reinforcement Learning for Retrieval-Augmented Reasoning ç°æœ‰æ£€ç´¢å¢å¼ºæ¨ç†æ–¹æ³•å› ä»…ä¾èµ–æœ€ç»ˆç­”æ¡ˆç›‘ç£ï¼Œæ˜“å¯¼è‡´æ¨¡å‹ç”Ÿæˆå†—é•¿ä½æ•ˆæ¨ç†é“¾å’Œå¹»è§‰ã€‚é€šè¿‡Kolmogorovå¤æ‚åº¦ç†è®ºé‡åŒ–æ¯ä¸ªæ¨ç†æ­¥éª¤çš„åŒå‘ä¿¡æ¯è·ç¦»â€”â€”æ—¢è¡¡é‡ä¸ç­”æ¡ˆçš„æ¥è¿‘ç¨‹åº¦ï¼ˆæ­£å‘ï¼‰ï¼Œä¹Ÿè¯„ä¼°å¯¹é—®é¢˜çš„å¥‘åˆåº¦ï¼ˆåå‘ï¼‰ï¼Œå¹¶é‡‡ç”¨å¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–è¿™ä¸¤ä¸ªç›®æ ‡ï¼šè®¾è®¡çº§è”å¥–åŠ±ç»“æ„é¼“åŠ±æ—©æœŸå»ºç«‹æ­£ç¡®æ–¹å‘ï¼Œç‹¬ç«‹è®­ç»ƒæ­£å‘/åå‘æ¨¡å‹åé€šè¿‡æƒé‡æ’å€¼èåˆï¼Œå®ç°ç»†ç²’åº¦çš„æ­¥éª¤çº§ç›‘ç£ï¼Œç”Ÿæˆæ›´ç²¾ç¡®ç®€æ´çš„æ¨ç†è¿‡ç¨‹ã€‚
- [2025.12] [[LLDS&MA-GRPO4Search-R1]](https://arxiv.org/abs/2512.04220) On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral ä¸ºäº†è§£å†³å†ç”¨GRPOè®­ç»ƒSearch-R1å‡ºç°çªç„¶å´©æºƒçš„ç°è±¡ï¼Œä½œè€…å‘ç°å…¶æ ¸å¿ƒåŸå› æ˜¯"æ‡’æƒ°ä¼¼ç„¶ä½ç§»"ï¼ˆLLDï¼‰â€”â€”ä¼˜åŒ–è¿‡ç¨‹ä¸­æ­£ç¡®ä¸é”™è¯¯å“åº”çš„ä¼¼ç„¶åº¦å‡å‡ºç°åœæ»æˆ–ä¸‹é™ï¼Œè¿›è€Œå¼•å‘è‡ªæˆ‘å¼ºåŒ–çš„"LLDæ­»äº¡èºæ—‹"ï¼Œå¯¼è‡´ä½ç½®ä¿¡åº¦å“åº”ã€æ¢¯åº¦è†¨èƒ€å’Œè®­ç»ƒå´©æºƒã€‚æå‡ºè½»é‡çº§ä¼¼ç„¶ä¿æŒæ­£åˆ™åŒ–LLDSï¼Œé€šè¿‡å“åº”çº§é—¨æ§ï¼ˆä»…å½“è½¨è¿¹æ€»ä¼¼ç„¶ä¸‹é™æ—¶æ¿€æ´»ï¼‰å’Œä»¤ç‰Œçº§é€‰æ‹©æ€§ï¼ˆä»…æƒ©ç½šå¯¼è‡´ä¸‹é™çš„ä»¤ç‰Œï¼‰ï¼Œç²¾å‡†æŠ‘åˆ¶LLDä¸”æœ€å°åŒ–å¯¹ä¼˜åŒ–çš„å¹²æ‰°ï¼Œå…¶å˜ä½“LLDS-MAæ©ç ç­”æ¡ˆä»¤ç‰Œä»¥é¼“åŠ±å¤šæ­¥æ¨ç†ã€‚ğŸŒŸ
- [2025.12] [[RouteRAG]](https://arxiv.org/abs/2512.09487) RouteRAG: Efficient Retrieval-Augmented Generation from Text and Graph via Reinforcement Learning è§£å†³RAGç¼ºä¹è‡ªé€‚åº”èƒ½åŠ›ï¼šå›¾ç»“æ„æˆ–æ··åˆæ£€ç´¢ç³»ç»Ÿä¾èµ–å›ºå®šæµç¨‹ï¼Œæ— æ³•åƒæ–‡æœ¬RAGé‚£æ ·é€šè¿‡å¼ºåŒ–å­¦ä¹ å®ç°å¤šè½®åŠ¨æ€æ£€ç´¢ï¼Œéš¾ä»¥åœ¨æ¨ç†è¿‡ç¨‹ä¸­æŒ‰éœ€è¡¥å……è¯æ®ï¼›æ£€ç´¢æ•ˆç‡é—®é¢˜ï¼šå›¾æ£€ç´¢è™½å¯¹å¤šè·³æ¨ç†è‡³å…³é‡è¦ï¼Œä½†è®¡ç®—æˆæœ¬è¿œé«˜äºæ–‡æœ¬æ£€ç´¢ï¼Œç°æœ‰æ–¹æ³•æ— æ³•æ ¹æ®æŸ¥è¯¢éœ€æ±‚çµæ´»é€‰æ‹©æ£€ç´¢æ–¹å¼ï¼Œå¯¼è‡´ä¸å¿…è¦çš„å¼€é”€ï¼›é€šè¿‡Search-R1çš„èŒƒå¼å®ç°ï¼Œä¸¤é˜¶æ®µRLè®­ç»ƒ[![[code]](https://img.shields.io/github/stars/YucanGuo/RouteRAG)](https://github.com/YucanGuo/RouteRAG)
- [2025.12] [[EKA]](https://arxiv.org/abs/2512.20144) Multi-hop Reasoning via Early Knowledge Alignment ç°æœ‰è¿­ä»£RAGç³»ç»Ÿå› æ¨¡å‹åœ¨ç¼ºä¹æ£€ç´¢è¯­æ–™ä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹åˆ†è§£é—®é¢˜ï¼Œå¯¼è‡´åˆå§‹æ¨ç†ç¼ºä¹ä¿¡æ¯åŸºç¡€ï¼Œæ˜“äº§ç”Ÿé”™è¯¯æ£€ç´¢å’Œçº§è”é”™è¯¯ã€‚ä¸ºæ­¤æå‡ºæ—©æœŸçŸ¥è¯†å¯¹é½ï¼ˆEKAï¼‰ï¼Œé€šè¿‡åœ¨è§„åˆ’é˜¶æ®µå‰æ‰§è¡Œé¦–æ¬¡æ£€ç´¢å¹¶å°†ç»“æœæ³¨å…¥æ¨¡å‹ï¼Œä½¿å…¶åç»­å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–çš„è¿­ä»£è¿‡ç¨‹å…·å¤‡ä¸Šä¸‹æ–‡åŸºç¡€ [![[code]](https://img.shields.io/github/stars/yxzwang/EarlyKnowledgeAlignment)](https://github.com/yxzwang/EarlyKnowledgeAlignment) 
- [2025.12] [[Laser]](https://arxiv.org/abs/2512.20458) Laser: Governing Long-Horizon Agentic Search via Structured Protocol and Context Register åŸºäºLLM/LRMçš„æ™ºèƒ½ä½“æœç´¢ç³»ç»Ÿé¢ä¸´ä¸¤ä¸ªæ ¸å¿ƒç“¶é¢ˆï¼šè‡ªç„¶è¯­è¨€æ¨ç†çš„è„†å¼±æ€§å’Œä¸Šä¸‹æ–‡çª—å£æ±¡æŸ“æº¢å‡ºï¼ŒLaseré€šè¿‡ç¬¦å·åŒ–åŠ¨ä½œåè®®+çŠ¶æ€å¯„å­˜å™¨ï¼Œå°†æ™ºèƒ½ä½“æœç´¢ä»"è‡ªç”±å‘æŒ¥çš„è‡ªç„¶è¯­è¨€å¯¹è¯"è½¬å˜ä¸º"å¯è§£æã€å¯å›æº¯ã€é«˜æ•ˆç‡çš„ç»“æ„åŒ–ç¨‹åºæ‰§è¡Œ"ï¼Œä»æ ¹æœ¬ä¸Šè§£å†³äº†é•¿ç¨‹æ¨ç†çš„ç¨³å®šæ€§å’Œå¯æ‰©å±•æ€§é—®é¢˜ã€‚å…è®­ç»ƒæ¨¡å¼ï¼šç›´æ¥é€šè¿‡æç¤ºå·¥ç¨‹é©±åŠ¨ï¼ˆåœ¨Qwen3-8b/32bä¸Šè¡¨ç°å¼ºåŠ²ï¼‰ï¼›RFTå¾®è°ƒï¼šä½¿ç”¨æ‹’ç»é‡‡æ ·å¾®è°ƒï¼ˆRejection Sampling Fine-Tuningï¼‰ï¼Œä»å¼ºæ¨¡å‹ï¼ˆDeepSeek-V3.1ï¼‰æ”¶é›†é«˜è´¨é‡ç»“æ„åŒ–è½¨è¿¹è¿›è¡Œè’¸é¦[![[code]](https://img.shields.io/github/stars/ShootingWong/Laser)](https://github.com/ShootingWong/Laser) 
- [2025.12] [[HGMem]](https://arxiv.org/abs/2512.23959) Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling æŠŠå¤šæ­¥ RAG çš„â€œå·¥ä½œè®°å¿†â€ä»å †å å­¤ç«‹äº‹å®çš„è¢«åŠ¨ä»“åº“å‡çº§ä¸ºå¯åŠ¨æ€æ¼”åŒ–çš„è¶…å›¾ï¼šç”¨è¶…è¾¹çµæ´»å»ºæ¨¡ n é˜¶å…³ç³»ï¼Œé€šè¿‡æ£€ç´¢-æ›´æ–°-æ’å…¥-åˆå¹¶å¾ªç¯è®©è®°å¿†ä¸æ–­é•¿å‡ºé«˜é˜¶å…³è”éª¨æ¶ï¼Œä»è€Œç»™åç»­æ¨ç†æä¾›ç»“æ„åŒ–ã€å…¨å±€åŒ–çš„çŸ¥è¯†æ”¯æ’‘ï¼Œæ˜¾è‘—æå‡é•¿æ–‡æœ¬å¤æ‚å…³ç³»ä¸å…¨å±€ç†è§£ä»»åŠ¡çš„æ•ˆæœ [![[code]](https://img.shields.io/github/stars/Encyclomen/HGMem)](https://github.com/Encyclomen/HGMem)
- [2026.01] [[ARR]](https://arxiv.org/abs/2601.04651) Adversarial Yet Cooperative: Multi-Perspective Reasoning in Retrieved-Augmented Language Models å¯¹æ£€ç´¢å¢å¼ºæ¨ç†æ¨¡å‹å•è§†è§’å±€é™å’Œè®­ç»ƒä¿¡å·ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºâ€œå¯¹æŠ—æ¨ç†RAGâ€æ¡†æ¶ï¼šè®©æ¨ç†å™¨ä¸éªŒè¯å™¨äº’è¯„é€»è¾‘ï¼Œå¹¶ç”¨è¿‡ç¨‹æ„ŸçŸ¥å¥–åŠ±åŒæ—¶ä¼˜åŒ–ä¸¤è€…ï¼Œæ— éœ€å¤–éƒ¨æ‰“åˆ†å³å¯æå‡å¤šæ­¥æ¨ç†è´¨é‡
- [2026.01] [[GRACE]](https://arxiv.org/abs/2601.04525) GRACE: Reinforcement Learning for Grounded Response and Abstention under Contextual Evidence é’ˆå¯¹RAGâ€œæ— è¯æ®ä¹Ÿç­”ã€è¯æ®ä¸è¶³å°±ç¼–â€çš„åŒé‡å¹»è§‰ï¼Œç”¨å¼‚æ„æ£€ç´¢å™¨è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ ·æœ¬ï¼Œå†ä»¥å¤šé˜¶æ®µé—¨æ§å¥–åŠ±å¼ºåŒ–å­¦ä¹ ï¼Œè®©æ¨¡å‹åŒæ—¶å­¦ä¼šè¯æ®æ¥åœ°ä¸ä¸»åŠ¨å¼ƒæƒï¼Œç”¨1/10æ ‡æ³¨æˆæœ¬å®ç°å‡†ç¡®ç‡ä¸æ‹’ç­”ç‡çš„æ–°å¹³è¡¡ [![[code]](https://img.shields.io/github/stars/YiboZhao624/Grace)](https://github.com/YiboZhao624/Grace)
- [2026.01] [[SmartSearch]](https://arxiv.org/abs/2601.04888) SmartSearch: Process Reward-Guided Query Refinement for Search Agents å‘ç° LLM æœç´¢æ™ºèƒ½ä½“è´¥åœ¨ä¸­é—´æŸ¥è¯¢ä¸å‡†ï¼Œäºæ˜¯ç”¨â€œè¿‡ç¨‹å¥–åŠ±+åŒå±‚ä¿¡ç”¨è¯„ä¼°â€å®æ—¶ç»™æ¯æ­¥æŸ¥è¯¢æ‰“åˆ†ï¼Œå¹¶åªé‡è®­åŠ£è´¨æŸ¥è¯¢åŠå…¶åç»­è½®æ¬¡ï¼›é…åˆâ€œæ¨¡ä»¿-å¯¹é½-æ³›åŒ–â€ä¸‰é˜¶æ®µè¯¾ç¨‹å­¦ä¹ ï¼Œè®©æ™ºèƒ½ä½“è‡ªä¼˜åŒ–æŸ¥è¯¢è´¨é‡ï¼Œåœ¨æ•ˆç‡ä¸å‡†ç¡®ç‡ä¸Šå…¨é¢è¶…è¶Šç°æœ‰åŸºçº¿ã€‚[![[code]](https://img.shields.io/github/stars/MYVAE/SmartSearch)](https://github.com/MYVAE/SmartSearch)
- [2026.01] [[PRISMA]](https://arxiv.org/abs/2601.05465) PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering å‘ç°ç«¯åˆ°ç«¯ RL å¤šè·³ RAG ä¼šâ€œæ£€ç´¢å´©æºƒâ€æ‰¾ä¸åˆ°æ¡¥æ¥è¯æ®ï¼Œåˆâ€œä¿¡ç”¨åˆ†é…å¼±â€æ˜“è¿‡æ‹Ÿåˆï¼Œäºæ˜¯æŠŠç³»ç»Ÿæ‹†æˆ Plan-Retrieve-Inspect-Solve-Memoize äº”æ™ºèƒ½ä½“ï¼šInspectoræä¾›åŸºäºæ¨ç†çš„åé¦ˆï¼Œç²¾ç‚¼è§„åˆ’è€…çš„åˆ†è§£æ–¹æ¡ˆï¼Œå¹¶å¼ºåˆ¶è¦æ±‚ Solver è¿›è¡ŒåŸºäºè¯æ®çš„æ¨ç†ï¼ŒSolver å¿…é¡»æ¥åœ°ï¼›ä¸¤é˜¶æ®µï¼šGRPO å…ˆåˆ†åˆ«æŠŠ Planner/Solver è®­æˆä¸“å®¶ï¼Œå†ç”¨ OARPO(è§‚å¯Ÿæ„ŸçŸ¥æ®‹å·®ç­–ç•¥ä¼˜åŒ–)è®© Inspector å­¦ä¼šéªŒè¯æ®ã€è§¦å‘ä¿®å¤ [![[code]](https://img.shields.io/github/stars/Ameame1/PRISIMA)](https://github.com/Ameame1/PRISIMA)
- [2026.01] [[CaRR & C-GRPO]](https://arxiv.org/abs/2601.06021) Chaining the Evidence: Robust Reinforcement Learning for Deep Search Agents with Citation-Aware Rubric Rewards æŒ‡å‡ºæ·±åº¦æœç´¢ RL åªç”¨äºŒå…ƒç»“æœå¥–åŠ±ä¼šèµ°æ·å¾„ã€ç¼–å¹»è§‰ï¼Œäºæ˜¯æŠŠå¤æ‚æé—®æ‹†æˆå¯éªŒè¯çš„å•è·³â€œè¯„åˆ†ç»†åˆ™â€ï¼Œè¦æ±‚æ™ºèƒ½ä½“æ˜¾å¼è¡¥å…¨éšè—å®ä½“ã€ç»™å‡ºæ­£ç¡®å¼•æ–‡å¹¶ä¸²æˆå®Œæ•´è¯æ®é“¾ï¼›å†é… C-GRPO ç®—æ³•è”åˆç»†åˆ™å¥–åŠ±ä¸ç»“æœå¥–åŠ±è®­ç»ƒï¼Œå…¨é¢æŠ‘åˆ¶æ·å¾„ï¼Œæå‡è¯æ®å®Œå¤‡æ€§ä¸äº‹å®å‡†ç¡®ç‡ [![[code]](https://img.shields.io/github/stars/THUDM/CaRR)](https://github.com/THUDM/CaRR)
- [2026.01] [[TreePS-RAG]](https://arxiv.org/abs/2601.06922) TreePS-RAG: Tree-based Process Supervision for Reinforcement Learning in Agentic RAG æŒ‡å‡ºä»…ç”¨æœ€ç»ˆå¥–åŠ±åš RL éš¾ä»¥å¯¹ä¸­é—´æ¨ç†æ­¥éª¤ä¿¡ç”¨åˆ†é…ï¼Œè€Œç¦»çº¿è¿‡ç¨‹ç›‘ç£åˆæ˜“åˆ†å¸ƒæ¼‚ç§»ï¼›äºæ˜¯æŠŠå¤šæ­¥æ£€ç´¢-æ¨ç†å±•å¼€æˆ rollout æ ‘ï¼ŒèŠ‚ç‚¹å³æ­¥éª¤ï¼Œç”¨åä»£ç»“å±€çš„è’™ç‰¹å¡æ´›ä¼°è®¡åœ¨çº¿è®¡ç®—æ¯æ­¥ä¼˜åŠ¿ï¼Œæ— éœ€äººå·¥ä¸­é—´æ ‡ç­¾
- [2026.01] [[Dr. Zero]](https://arxiv.org/abs/2601.07055) Dr. Zero: Self-Evolving Search Agents without Training Data é«˜è´¨é‡è®­ç»ƒæ•°æ®éš¾è·ä¸”å¤šè½®æœç´¢æ™ºèƒ½ä½“åœ¨â€œæ— æ•°æ®è‡ªè¿›åŒ–â€ä¸­é—®é¢˜å•ä¸€ã€è®¡ç®—çˆ†ç‚¸ï¼Œäºæ˜¯è®©åŒä¸€åŸºæ¨¡å‹çš„â€œå‘½é¢˜è€…â€ä¸â€œè§£é¢˜è€…â€äº’æï¼šå‘½é¢˜è€…ä¸æ–­ç”Ÿæˆæ›´éš¾å´å¯è§£çš„æ–°é¢˜ï¼Œè§£é¢˜è€…ç”¨ hop-grouped ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆHRPOï¼‰æŒ‰ç»“æ„èšç±»æ‰¹è®­ï¼Œçœæ‰é€é¢˜éš¾åº¦è¯„ä¼°çš„é‡‡æ ·å¼€é”€ï¼›å…¨ç¨‹é›¶äººå·¥æ•°æ®ï¼Œè‡ªè¿›åŒ–å‡ºçš„æ™ºèƒ½ä½“åœ¨å¤šé¡¹ä»»åŠ¡ä¸Šè¿½å¹³ç”šè‡³è¶…è¶Šå…¨ç›‘ç£æ–¹æ¡ˆ [![[code]](https://img.shields.io/github/stars/facebookresearch/drzero)](https://github.com/facebookresearch/drzero)
- [2026.01] [[RAGShaper]](https://arxiv.org/abs/2601.08699v1) RAGShaper: Eliciting Sophisticated Agentic RAG Skills via Automated Data Synthesis é’ˆå¯¹ Agentic RAG ç³»ç»Ÿç¼ºä¹â€œå¸¦å™ªå£°â€è®­ç»ƒæ•°æ®çš„ç—›ç‚¹ï¼Œæå‡º RAGShaper æ¡†æ¶ï¼šå…ˆç”¨ InfoCurator å›´ç»•ç§å­å®ä½“æ£€ç´¢å¹¶ç”Ÿæˆæ„ŸçŸ¥-è®¤çŸ¥ä¸¤çº§å¹²æ‰°æ–‡æ¡£ï¼Œå†è®©æ•™å¸ˆæ™ºèƒ½ä½“åœ¨â€œå—é™å¯¼èˆªâ€ä¸‹å®Œæˆå¤šè·³é—®ç­”ï¼Œè‡ªåŠ¨äº§å‡ºå«çº é”™ã€æŠ—å™ªè¡Œä¸ºçš„è½¨è¿¹ï¼Œæ— éœ€äººå·¥æ ‡æ³¨å³å¯å¤§è§„æ¨¡åˆæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®ã€‚
- [2026.01] [[EvoFSM]](https://arxiv.org/abs/2601.09465) EvoFSM: Controllable Self-Evolution for Deep Research with Finite State Machines æŠŠè‡ªæ¼”åŒ–ä»æ˜“å¤±æ§çš„â€œè‡ªç”±æ”¹ä»£ç â€æ”¶æŸåˆ°æ˜¾å¼æœ‰é™çŠ¶æ€æœºï¼Œå°†ä¼˜åŒ–ç©ºé—´è§£è€¦ä¸ºå®è§‚ Flowï¼ˆçŠ¶æ€è½¬ç§»ï¼‰ä¸å¾®è§‚ Skillï¼ˆçŠ¶æ€è¡Œä¸ºï¼‰ï¼Œç”¨æ‰¹è¯„æœºåˆ¶æŒ‡å¯¼å°‘é‡å—æ§æ“ä½œè¿­ä»£ FSMï¼Œå¹¶é…è‡ªæˆ‘æ¼”åŒ–è®°å¿†åº“ï¼ŒæŠŠæˆåŠŸè½¨è¿¹è½¬ä¸ºå¯å¤ç”¨å…ˆéªŒã€å¤±è´¥æ¨¡å¼è½¬ä¸ºçº¦æŸ [![[code]](https://img.shields.io/github/stars/QuantaAlpha/EvoFSM)](https://github.com/QuantaAlpha/EvoFSM)
- [2026.01] [[BAPO]](https://arxiv.org/abs/2601.11037) BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search ç”¨ RL é©±åŠ¨çš„æœç´¢æ™ºèƒ½ä½“è™½èƒ½è¿­ä»£æ£€ç´¢ã€æå‡ç­”æ¡ˆå‡†ç¡®ç‡ï¼Œå´æ™®éç¼ºä¹â€œè‡ªçŸ¥ä¹‹æ˜â€â€”â€”åœ¨è¯æ®ä¸è¶³æˆ–æ¨ç†åˆ°å¤´æ—¶ä»å¼ºè¡Œç»™å‡ºçœ‹ä¼¼åˆç†å´ä¸å¯é çš„ç­”æ¡ˆï¼Œæå°‘ä¸»åŠ¨å›ç­”â€œæˆ‘ä¸çŸ¥é“â€(IDK)ï¼Œç»™é«˜é£é™©åœºæ™¯å¸¦æ¥éšæ‚£ã€‚æå‡º BAPOï¼ˆBoundary-Aware Policy Optimizationï¼‰æ¡†æ¶ï¼Œé€šè¿‡ä¸¤é¡¹æœºåˆ¶å®ç°â€œè¾¹ç•Œæ„ŸçŸ¥â€ï¼šåŸºäºç»„å¯¹æ¯”çš„è¾¹ç•Œå¥–åŠ±â€”â€”ä»…å½“åŒç»„å†…å¤šæ¡è½¨è¿¹å‡æ— æ³•é€¼è¿‘æ­£ç¡®ç­”æ¡ˆæ—¶æ‰ç»™ IDK æ­£å‘ä¿¡å·ï¼Œé¿å…è¯¯å¥–ï¼›è‡ªé€‚åº”å¥–åŠ±è°ƒåˆ¶å™¨â€”â€”è®­ç»ƒåˆæœŸæš‚åœè¯¥å¥–åŠ±ï¼Œé˜²æ­¢ agent æŠŠ IDK å½“æ·å¾„æ»¥ç”¨ã€‚[![[code]](https://img.shields.io/github/stars/Liushiyu-0709/BAPO-Reliable-Search)](https://github.com/Liushiyu-0709/BAPO-Reliable-Search)
- [2026.01] [[Agentic-R]](https://arxiv.org/abs/2601.11888) Agentic-R: Learning to Retrieve for Agentic Search ç°æœ‰â€œæœç´¢æ™ºèƒ½ä½“â€å¤šè½®æ£€ç´¢ä¾èµ–çš„ä»æ˜¯é¢å‘å•è½® RAG çš„ç›¸ä¼¼åº¦æ£€ç´¢å™¨ï¼Œæ— æ³•ä¿è¯ä¸­é—´ passage æ—¢å±€éƒ¨ç›¸å…³åˆæœ€ç»ˆå¯¼å‘æ­£ç¡®ç­”æ¡ˆï¼ŒäºŸéœ€ä¸“ä¸ºå¤šè½® agentic search å®šåˆ¶çš„æ£€ç´¢å™¨ã€‚æŠŠæ£€ç´¢å™¨ä»â€œå•è½®ç›¸ä¼¼â€å‡çº§ä¸ºâ€œå¤šè½®æœ‰ç”¨â€ï¼šå…ˆç”¨ LLM æ‰“åˆ†è¡¡é‡å±€éƒ¨ç›¸å…³ï¼Œå†ç”¨â€œä»£å…¥è¯¥æ®µè½èƒ½å¦æ¨å¾—æœ€ç»ˆæ­£ç¡®ç­”æ¡ˆâ€è¡¡é‡å…¨å±€è´¡çŒ®ï¼Œè‡ªåŠ¨æ„å»ºæ­£è´Ÿä¾‹åšå¯¹æ¯”å­¦ä¹ ï¼›åŒæ—¶è®©æœç´¢ agent ä¸æ£€ç´¢å™¨åŒå‘è¿­ä»£ï¼Œagent äº§å‡ºæ›´é«˜è´¨é‡æŸ¥è¯¢åå“ºæ£€ç´¢å™¨ï¼Œä¸¤è½®åå¾—åˆ°è·¨ agent é€šç”¨ã€EM æå‡ä¸”å‡å°‘ 10â€“15% æœç´¢æ­¥æ•°çš„â€œè‡ªæˆ‘è¿›åŒ–â€æ£€ç´¢å™¨ã€‚ [![[code]](https://img.shields.io/github/stars/8421BCD/Agentic-R)](https://github.com/8421BCD/Agentic-R)
- [2026.01] [[SearchGym]](https://arxiv.org/abs/2601.14615) SearchGym: Bootstrapping Real-World Search Agents via Cost-Effective and High-Fidelity Environment Simulation é€šè¿‡æ„å»ºé«˜ä¿çœŸæ¨¡æ‹Ÿç¯å¢ƒè§£å†³æœç´¢æ™ºèƒ½ä½“è®­ç»ƒä¸­çš„æ•°æ®ä¸å¯¹é½é—®é¢˜ï¼Œç”¨å¯éªŒè¯çŸ¥è¯†å›¾è°±å’Œå¯¹é½è¯­æ–™åº“æ›¿ä»£æ˜‚è´µçš„çœŸå®APIäº¤äº’ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šå¼•å…¥SearchGym-RLï¼Œä¸€ç§è¯¾ç¨‹å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡çº¯åŒ–åé¦ˆé€æ­¥ä¼˜åŒ–æ™ºèƒ½ä½“ç­–ç•¥ï¼Œä»åŸºæœ¬äº¤äº’å‘å±•åˆ°å¤æ‚çš„é•¿è¿œè§„åˆ’ã€‚ [![[code]](https://img.shields.io/github/stars/JIA-Lab-research/SearchGym)](https://github.com/JIA-Lab-research/SearchGym)
- [2026.01] [[SAGE]](https://arxiv.org/abs/2601.18202v1) SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback æ·±åº¦æœç´¢æ™ºèƒ½ä½“éœ€è¦è·¨æ–‡æ¡£å¤šè·³æ¨ç†ï¼Œä½†äººå·¥æ ‡æ³¨é•¿è½¨è¿¹æˆæœ¬æé«˜ï¼Œç°æœ‰åˆæˆæ•°æ®åˆéš¾æ§éš¾åº¦ä¸è´¨é‡ï¼Œå¯¼è‡´è®­ç»ƒæ ·æœ¬ç¨€ç¼ºä¸”åˆ†å¸ƒå¤±è¡¡ã€‚æå‡º SAGEâ€”â€”å¯è½¬å‘çš„ Agentic æ•°æ®ç”Ÿæˆ pipelineï¼šç”Ÿæˆå™¨å…ˆè‰æ‹Ÿ QA â†’ æœç´¢ agent å®è·‘è½¨è¿¹ç»™å‡ºâ€œèƒ½å¦ç­”å¯¹ã€éš¾åº¦æ˜¯å¦åŒ¹é…â€çš„æ‰§è¡Œåé¦ˆ â†’ ç”Ÿæˆå™¨æ®æ­¤å¤šè½®ç²¾ä¿®é—®é¢˜ä¸ç­”æ¡ˆï¼Œç›´è‡³æ»¡è¶³é¢„è®¾éš¾åº¦ã€‚ intrinsic è¯„ä¼°æ˜¾ç¤ºç”Ÿæˆé¢˜éœ€å¤šæ ·ç­–ç•¥ä¸”éš¾åº¦/æ­£ç¡®ç‡æ˜¾è‘—æå‡ï¼›extrinsic ä¸Šï¼Œç”¨ SAGE æ•°æ®è®­ç»ƒçš„ agent åœ¨ä¸»æµæ·±åº¦æœç´¢åŸºå‡†è·æœ€é«˜ 23 % ç›¸å¯¹æå‡ï¼Œå¹¶å¯é›¶æ ·æœ¬è¿ç§»åˆ° Google æœç´¢ [![[code]](https://img.shields.io/github/stars/carriex/sage)](https://github.com/carriex/sage)
- [2026.01] [[PaperSearchQA]](https://arxiv.org/abs/2601.18207v1) PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR ç°æœ‰ RLVR æœç´¢æ™ºèƒ½ä½“åªåœ¨é€šç”¨ QA ä¸ŠéªŒè¯â€œæœ€ç»ˆç­”æ¡ˆå¯¹ä¸å¯¹â€ï¼Œç¼ºä¹é¢å‘ç§‘å­¦æ–‡çŒ®çš„æ·±å±‚æŠ€æœ¯é—®ç­”ï¼Œéš¾ä»¥æ»¡è¶³ç§‘ç ”å·¥ä½œè€…ä¸æœªæ¥â€œAI ç§‘å­¦å®¶â€çš„çœŸå®éœ€æ±‚ã€‚å¦‚ä½•æ„å»ºå¤§è§„æ¨¡ã€å¯éªŒè¯reward çš„ç§‘å­¦æ–‡çŒ®æœç´¢ç¯å¢ƒï¼Œè®©æ™ºèƒ½ä½“å­¦ä¼šåœ¨ 1600 ä¸‡ç¯‡ç”Ÿç‰©åŒ»å­¦æ‘˜è¦é‡Œåšå¤æ‚æ£€ç´¢ä¸æ¨ç†ï¼Œå¹¶ç³»ç»Ÿè¯„ä¼°å…¶è§„åˆ’ã€è‡ªæ£€ç­‰èƒ½åŠ›ã€‚å‘å¸ƒ PaperSearchQAâ€”â€”å« 1600 ä¸‡æ‘˜è¦çš„æœç´¢è¯­æ–™ + 6 ä¸‡å¯éªŒè¯äº‹å®é—®ç­”å¯¹ + è¯„æµ‹åŸºå‡†ï¼›åŸºäº Search-R1 æ¡†æ¶è®­ç»ƒæ™ºèƒ½ä½“ï¼Œä»¥â€œæœ€ç»ˆç­”æ¡ˆ EMâ€ä¸ºå¯éªŒè¯å¥–åŠ±ï¼Œæ˜¾è‘—ä¼˜äºé RL æ£€ç´¢åŸºçº¿ï¼Œå¹¶å±•ç°å‡ºè§„åˆ’ã€æ¨ç†ã€è‡ªéªŒè¯ç­‰å¯è§£é‡Šè¡Œä¸ºï¼›æ•°æ®ä¸ä»£ç å…¨éƒ¨å¼€æºï¼Œä¸”åˆ›å»ºæµç¨‹å¯ä½æˆæœ¬æ‰©å±•åˆ°å…¶ä»–ç§‘å­¦é¢†åŸŸ [![[code]](https://img.shields.io/github/stars/jmhb0/PaperSearchQA)](https://github.com/jmhb0/PaperSearchQA) [![Dataset](https://img.shields.io/badge/Dataset-HuggingFace-yellow)](https://huggingface.co/datasets/jmhb/PaperSearchQA)
- [2026.01] [[Dep-Search]](https://arxiv.org/abs/2601.18771v1) Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory ç°æœ‰â€œæœç´¢+æ¨ç†â€æ¡†æ¶å…¨é éšå¼è‡ªç„¶è¯­è¨€ä¸²æ¥å†³ç­–æœä»€ä¹ˆã€æ€ä¹ˆç”¨ï¼Œå¯¼è‡´å­é—®é¢˜ä¾èµ–å…³ç³»æ··ä¹±ã€æ—§çŸ¥è¯†æ— æ³•é‡ç”¨ã€RL ä¿¡å·ç¨€ç–ï¼Œéš¾ä»¥å­¦ä¼šæœ€ä¼˜æœç´¢ç­–ç•¥ã€‚æå‡º Dep-Searchï¼Œç”¨ä¾èµ–æ„ŸçŸ¥çš„ç»“æ„åŒ–åˆ†è§£å°†ä¸»é—®é¢˜æ‹†æˆå¸¦å…ˆåä¾èµ–çš„å­å›¾ï¼Œå¼•å…¥æŒä¹…è®°å¿†åº“ä¿å­˜å·²è·äº‹å®ï¼›é€šè¿‡ GRPO è”åˆä¼˜åŒ–â€œä½•æ—¶æ£€ç´¢/å¤ç”¨è®°å¿†/æ›´æ–°è®°å¿†â€çš„æ˜¾å¼åŠ¨ä½œï¼Œå®ç°ä¾èµ–-æ£€ç´¢-è®°å¿†ä¸€ä½“åŒ–æ§åˆ¶ï¼Œåœ¨ 7 ä¸ª QA æ•°æ®é›†ä¸Šæ˜¾è‘—è¶…è¶Šå¼ºåŸºçº¿ã€‚
- [2026.01] [[ProRAG]](https://arxiv.org/abs/2601.21912v1) ProRAG: Process-Supervised Reinforcement Learning for Retrieval-Augmented Generation é€šè¿‡MCTSæ„å»ºè¿‡ç¨‹å¥–åŠ±æ¨¡å‹å¹¶å¼•å…¥åŒç²’åº¦ä¼˜åŠ¿æœºåˆ¶ï¼Œè§£å†³äº†é•¿ç¨‹å¤šè·³RAGä»»åŠ¡ä¸­åŸºäºç»“æœçš„RLå¥–åŠ±ç¨€ç–å’Œä¿¡ç”¨åˆ†é…å›°å¢ƒï¼Œåœ¨5ä¸ªå¤šè·³æ¨ç†åŸºå‡†ä¸Šæ˜¾è‘—è¶…è¶Šå¼ºåŸºçº¿ï¼Œç‰¹åˆ«åœ¨å¤„ç†å¤æ‚é•¿ç¨‹ä»»åŠ¡æ—¶è¡¨ç°å‡ºä¼˜ç§€çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚ [![[code]](https://img.shields.io/github/stars/lilinwz/ProRAG)](https://github.com/lilinwz/ProRAG)
- [2026.01] [[JADE]](https://arxiv.org/abs/2601.21916v1) JADE: Bridging the Strategic-Operational Gap in Dynamic Agentic RAG
  * åŠ¨æœºï¼šç°æœ‰ Agentic RAG èŒƒå¼é¢ä¸´å…³é”®äºŒåˆ†å›°å¢ƒï¼šè¦ä¹ˆåœ¨åˆšæ€§å›ºå®šå›¾æ¶æ„å†…è”åˆä¼˜åŒ–æ¨¡å—ï¼ˆé™æ€è”åˆä¼˜åŒ–ï¼‰ï¼Œä¸§å¤±åŠ¨æ€é€‚åº”èƒ½åŠ›ï¼›è¦ä¹ˆèµ‹äºˆåŠ¨æ€è§„åˆ’èƒ½åŠ›å´å°†æ‰§è¡Œå™¨è§†ä¸ºå†»ç»“é»‘ç›’ï¼ˆåŠ¨æ€è§£è€¦ä¼˜åŒ–ï¼‰ï¼Œå¯¼è‡´"æˆ˜ç•¥-è¿è¥ä¸åŒ¹é…"â€”â€”è§„åˆ’å™¨è®¾è®¡çš„ç²¾å¦™ç­–ç•¥å› æ‰§è¡Œå™¨æœªååŒè®­ç»ƒè€Œæ— æ³•å®ç°ï¼Œåè€Œé€ æˆè´Ÿé¢æ€§èƒ½æ”¶ç›Šä¸”å¢åŠ ç³»ç»Ÿå¤æ‚åº¦ã€‚
    1. é™æ€æ–¹æ³•ï¼ˆå¦‚ MMOA-RAGï¼‰å—é™äºå›ºå®šå·¥ä½œæµç¨‹ï¼Œæ— æ³•å¤„ç†éœ€è¦å¤šå˜æ¨ç†è·¯å¾„çš„å¤æ‚å¤šè·³æŸ¥è¯¢ï¼›
    2. è§£è€¦æ–¹æ³•ï¼ˆå¦‚ MAO-ARAGï¼‰ä»…ä¼˜åŒ–è§„åˆ’å™¨è€Œå†»ç»“æ‰§è¡Œå™¨ï¼Œå¯¼è‡´è§„åˆ’ä¸å®é™…æ‰§è¡Œèƒ½åŠ›è„±èŠ‚ï¼›
    3. å•ä½“æ–¹æ³•ï¼ˆå¦‚ Search-R1ï¼‰è™½æä¾›ç«¯åˆ°ç«¯çµæ´»æ€§ï¼Œä½†ç¼ºä¹ç»“æ„å…ˆéªŒå¯¼è‡´è®­ç»ƒä¸ç¨³å®šï¼Œåœ¨å·¨å¤§ä¸Šä¸‹æ–‡çª—å£ä¸­åŒæ—¶å­¦ä¹ æ¨ç†ã€æŸ¥è¯¢å’Œè¿‡æ»¤ä¼šé™·å…¥ä¼˜åŒ–å›°å¢ƒã€‚
  * æå‡ºçš„æ–¹æ³•ï¼š JADEï¼ˆJoint Agentic Dynamic Executionï¼‰ï¼Œæ ¸å¿ƒåŒ…æ‹¬ï¼š
    1. å‚æ•°å…±äº«çš„ MSMDP å»ºæ¨¡ï¼šå°†åŠ¨æ€ RAG å»ºæ¨¡ä¸ºå¤šæ™ºèƒ½ä½“åŠé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼Œè§„åˆ’å™¨å’Œæ‰§è¡Œå™¨ï¼ˆæŸ¥è¯¢é‡å†™ã€æ–‡æ¡£é€‰æ‹©ã€ç­”æ¡ˆç”Ÿæˆç­‰ï¼‰å…±äº«åŒä¸€ä¸ª LLM ä¸»å¹²ï¼Œé€šè¿‡è§’è‰²ç‰¹å®šæç¤ºåŒºåˆ†åŠŸèƒ½ï¼›
    2. ç»Ÿä¸€ç»éªŒå›æ”¾ç¼“å†²ï¼šå°†å¼‚æ„çš„è§„åˆ’å’Œæ‰§è¡Œè½¬ç§»æ•°æ®èšåˆåˆ°å…±äº«ç¼“å†²åŒºï¼Œä½¿ç”¨ PPO è¿›è¡Œç«¯åˆ°ç«¯è”åˆä¼˜åŒ–ï¼›
    3. åŒå±‚å¥–åŠ±æœºåˆ¶ï¼šå…¨å±€å…±äº«å¥–åŠ±ï¼ˆæœ€ç»ˆç­”æ¡ˆè´¨é‡å‡å»è®¡ç®—æˆæœ¬ï¼‰ä¿ƒè¿›å›¢é˜Ÿåä½œè§£å†³ä¿¡ç”¨åˆ†é…é—®é¢˜ï¼Œå±€éƒ¨æ ¼å¼æƒ©ç½šç¡®ä¿å„è§’è‰²è¾“å‡ºç»“æ„åˆè§„ï¼›
    4. åŠ¨æ€å·¥ä½œæµç¼–æ’ï¼šè§„åˆ’å™¨æ ¹æ®æŸ¥è¯¢å¤æ‚åº¦è‡ªé€‚åº”é€‰æ‹©"ä¸²è¡Œåˆ†è§£"ã€"å¹¶è¡Œåˆ†è§£"æˆ–"ç›´æ¥æ±‚è§£"ç­‰å·¥ä½œæµæ‹“æ‰‘ã€‚
