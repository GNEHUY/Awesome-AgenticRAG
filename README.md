<div align="center">
  <!-- <p align="center"> -->
  <h1 align="center"><strong>Awesome-AgenticRAG</strong></h1>
</div>

ğŸ”¬ åˆ—ä¸¾ä¸€äº›å…³äºAgenticRAGçš„ç³»åˆ—æ–‡ç« ï¼Œä»¥2025å¹´å¼€å§‹ï¼ŒåŒ…æ‹¬Search-O1ï¼ŒSearch-R1

- [2025.01] [[Search-o1]](https://arxiv.org/abs/2501.05366) Search-o1: Agentic Search-Enhanced Large Reasoning Models å¢å¼ºå…·æœ‰ç±»ä¼¼O1æ¨ç†æ¨¡å¼çš„LRMsçš„è‡ªä¸»æ£€ç´¢èƒ½åŠ›ï¼Œä½¿æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­èƒ½åŠ¨æ€æ£€ç´¢å¤–éƒ¨çŸ¥è¯†ï¼Œä»è€Œæé«˜æ¨ç†çš„å‡†ç¡®æ€§å’Œå¯é æ€§ [![[code]](https://img.shields.io/github/stars/sunnynexus/Search-o1)](https://github.com/sunnynexus/Search-o1)
- [2025.02] [[O1 Embedder]](https://arxiv.org/abs/2502.07555) O1 Embedder: Let Retrievers Think Before Action å·²ç»æœ‰å¾ˆå¤šè®­ç»ƒLLMä½œä¸ºEmbedderçš„å·¥ä½œï¼Œå¦‚ä½•è®©Embedderåœ¨æ£€ç´¢ç›®æ ‡æ–‡æ¡£ä¹‹å‰ç”Ÿæˆå¯¹è¾“å…¥æŸ¥è¯¢æœ‰ç”¨çš„thoughtsï¼Œç±»ä¼¼äºä¸€ä¸ªæ¨ç†çš„è¿‡ç¨‹ï¼Ÿ[![[code]](https://img.shields.io/github/stars/RuiranYan/o1embedder)](https://github.com/RuiranYan/o1embedder)
- [2025.03] [DeepRetrieval](https://arxiv.org/abs/2503.00223) DeepRetrieval: Hacking Real Search Engines and Retrievers with Large Language Models via Reinforcement Learning ä¸å‰é¢åŸºäºç­”æ¡ˆåŒ¹é…åº¦ä½œä¸ºå¥–åŠ±ä¿¡å·ä¸åŒ(å‰é¢ä¸»è¦æ˜¯RAGçš„QAä»»åŠ¡)ï¼Œè¯¥å·¥ä½œä¸»è¦èšç„¦åœ¨æ£€ç´¢ä»»åŠ¡ï¼Œä»¥æ£€ç´¢æŒ‡æ ‡ä½œä¸ºå¥–åŠ±ä¿¡å·ï¼ŒLLMé€šè¿‡æŸ¥è¯¢å¢å¼ºçš„æ–¹å¼ï¼Œè¡¥å……åŸå§‹æŸ¥è¯¢çš„è¯­ä¹‰ï¼Œç„¶åè¿›è¡Œæ£€ç´¢ [![[code]](https://img.shields.io/github/stars/pat-jj/DeepRetrieval)](https://github.com/pat-jj/DeepRetrieval)
- [2025.03] [[Search-R1]](https://arxiv.org/abs/2503.09516) Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning æ”¶åˆ°R1çš„å¯å‘ï¼Œå°†å¼ºåŒ–å­¦ä¹ æ‰©å±•åˆ°RAGåœºæ™¯ï¼Œå°†æœç´¢å¼•æ“å»ºæ¨¡ä¸ºå¼ºåŒ–å­¦ä¹ ç¯å¢ƒçš„ä¸€éƒ¨åˆ†ï¼Œä½¿LLMèƒ½é€šè¿‡è¯•é”™è‡ªä¸»å­¦ä¹ ï¼›ä»…ç”¨æœ€ç»ˆç­”æ¡ˆæ­£ç¡®æ€§ä½œä¸ºå¥–åŠ±ä¿¡å·ï¼Œåˆ›æ–°æ£€ç´¢å†…å®¹æ©ç  [![[code]](https://img.shields.io/github/stars/PeterGriffinJin/Search-R1)](https://github.com/PeterGriffinJin/Search-R1)
- [2025.03] [[R1-Searcher]](https://arxiv.org/abs/2503.05592) R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning ä¸Search-R1ç±»ä¼¼ï¼Œä¸è¿‡é‡‡ç”¨çš„æ˜¯åŸºäºä¸¤é˜¶æ®µRLæ¡†æ¶ï¼Œé€šè¿‡è‡ªä¸»è°ƒç”¨å¤–éƒ¨æœç´¢å·¥å…·å¢å¼ºLLMçš„å›ç­”èƒ½åŠ›ï¼Œæ— è¿‡ç¨‹å¥–åŠ±æˆ–è’¸é¦ã€‚ä»…ä¾èµ–æœ€ç»ˆå¥–åŠ±ã€‚ [![[code]](https://img.shields.io/github/stars/RUCAIBox/R1-Searcher)](https://github.com/RUCAIBox/R1-Searcher)
- [2025.03] [[ReSearch]](https://arxiv.org/abs/2503.19470) ReSearch: Learning to Reason with Search for LLMs via Reinforcement Learning åŸºæœ¬å’ŒSearch-R1ä¸€æ ·ï¼Œä¸åŒç‚¹åœ¨äºè€ƒè™‘äº†æ ¼å¼å¥–åŠ±ï¼ŒåŒæ—¶ç”¨çš„æ˜¯F1 score [![[code]](https://img.shields.io/github/stars/Agent-RL/ReSearch)](https://github.com/Agent-RL/ReSearch)
- [2025.03] [[ReAgent]](https://arxiv.org/abs/2503.06951) ReAgent: Reversible Multi-Agent Reasoning for  Knowledge-Enhanced Multi-Hop QA é€šè¿‡å¼•å…¥å¤šæ™ºèƒ½ä½“å¯é€†å›æº¯æ¨ç†æœºåˆ¶ï¼Œè§£å†³äº†å¤šè·³é—®ç­”ä¸­é”™è¯¯ç§¯ç´¯å’Œä¸å¯çº æ­£çš„é—®é¢˜ã€‚ [![[code]](https://img.shields.io/github/stars/astridesa/ReAgent)](https://github.com/astridesa/ReAgent)
- [2025.04] [[DeepResearcher]](https://arxiv.org/abs/2504.03160) DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-World Environments æ˜¯ç°æœ‰æœç´¢ä»£ç†åœ¨å®é™…ç¯å¢ƒä¸­æ‰©å±•å›°éš¾ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ åœ¨çœŸå®ç¯å¢ƒä¸­æ‰©å±•æ·±åº¦ç ”ç©¶èƒ½åŠ›ï¼Œç¼ºå°‘åœ¨çœŸå®ç½‘ç»œç¯å¢ƒä¸­ï¼Œåº”å¯¹ç¯å¢ƒåŠ¨æ€æ€§ï¼Œä¸å¯é¢„æµ‹æ€§ï¼Œå™ªå£°ã€æœç´¢ç½‘é¡µè´¨é‡å·®å¼‚å’Œå†…å®¹æ ¼å¼é—®é¢˜çš„å¼ºå¤§Agentæ¡†æ¶ï¼Œä¸ä»…æœ‰Searchè¿˜æœ‰Browse [![[code]](https://img.shields.io/github/stars/GAIR-NLP/DeepResearcher)](https://github.com/GAIR-NLP/DeepResearcher)
- [2025.05] [[AutoRefine]](https://arxiv.org/pdf/2505.11277) Search and Refine During Think: Facilitating Knowledge Refinement for Improved Retrieval-Augmented Reasoning Search-R1æ£€ç´¢åˆ°çš„æ–‡æ¡£å¾€å¾€åŒ…å«æ— å…³å†…å®¹ï¼Œå¯èƒ½å½±å“åˆ°æ¨¡å‹æœ‰æ•ˆåˆ©ç”¨æ–°çš„çŸ¥è¯†ã€‚å¯ä»¥è€ƒè™‘è¾¹æ£€ç´¢ï¼Œè¾¹ç²¾ç‚¼çš„æ–¹å¼ï¼Œä½¿æ¨¡å‹åœ¨æ£€ç´¢è¿‡ç¨‹ä¸­è‡ªæˆ‘è¿›åŒ–ã€‚åŒæ—¶ç²¾ç‚¼è¿‡ç¨‹æä¾›å¥–åŠ±ï¼Œé¿å…ä»…ç»“æœå¥–åŠ± [![[code]](https://img.shields.io/github/stars/syr-cn/AutoRefine)](https://github.com/syr-cn/AutoRefine)
- [2025.05] [[IKEA]](https://arxiv.org/abs/2505.07596) IKEA: Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent è§£å†³ç°æœ‰æœç´¢ä»£ç†è¿‡åº¦ä¾èµ–å¤–éƒ¨æœç´¢ã€æœªå……åˆ†åˆ©ç”¨å†…éƒ¨çŸ¥è¯†çš„é—®é¢˜ï¼Œæå‡ºå¼ºåŒ–å­¦ä¹ çš„å†…å¤–éƒ¨çŸ¥è¯†ååŒæ¨ç†ä»£ç†ï¼Œè¯†åˆ«çŸ¥è¯†è¾¹ç•Œï¼Œä¼˜å…ˆä½¿ç”¨å†…éƒ¨çŸ¥è¯†ï¼Œå‡å°‘å†—ä½™æ£€ç´¢å’ŒçŸ¥è¯†å†²çª [![[code]](https://img.shields.io/github/stars/hzy312/knowledge-r1)](https://github.com/hzy312/knowledge-r1)
- [2025.05] [[ZeroSearch]](https://arxiv.org/abs/2505.04588) ZeroSearch: Incentivize the Search Capability of LLMs without Searching è§£å†³RLè®­ç»ƒæœç´¢ä»£ç†æ—¶é¢ä¸´çš„æ–‡æ¡£è´¨é‡ä¸å¯æ§å’ŒAPIæˆæœ¬é«˜æ˜‚ä¸¤å¤§æŒ‘æˆ˜ï¼Œæ— éœ€çœŸå®æœç´¢ï¼Œç›´æ¥ç”¨LLMæ¨¡æ‹Ÿæœç´¢å¼•æ“ï¼Œå¼•å…¥è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œåœ¨é™ä½88%æˆæœ¬çš„åŒæ—¶æ€§èƒ½è¶…è¿‡ä¾èµ–çœŸå®æœç´¢çš„æ–¹æ³• [![[code]](https://img.shields.io/github/stars/Alibaba-NLP/ZeroSearch)](https://github.com/Alibaba-NLP/ZeroSearch)
- [2025.05] [[s3]](https://arxiv.org/abs/2505.14146) s3: You Don't Need That Much Data to Train a Search Agent via RL è§£å†³ç°æœ‰æ–¹æ³•è¦ä¹ˆä¼˜åŒ–æ£€ç´¢æŒ‡æ ‡å¿½ç•¥ä¸‹æ¸¸æ•ˆç”¨ï¼Œè¦ä¹ˆç«¯åˆ°ç«¯è®­ç»ƒå¯¼è‡´æœç´¢ä¸ç”Ÿæˆçº ç¼ çš„é—®é¢˜ï¼Œæå‡ºè½»é‡çº§æ¡†æ¶è§£è€¦æœç´¢å™¨å’Œç”Ÿæˆå™¨ï¼Œä»…ç”¨2.4kè®­ç»ƒæ ·æœ¬å®ç°å¼ºå¤§æ€§èƒ½ï¼Œæå‡ºGain Beyond RAGå¥–åŠ± [![[code]](https://img.shields.io/github/stars/pat-jj/s3)](https://github.com/pat-jj/s3)
- [2025.05] [[StepSearch]](https://arxiv.org/pdf/2505.15107) StepSearch: Igniting LLMs Search Ability via Step-Wise Proximal Policy Optimization ç›®å‰Search-R1ç­‰ç°æœ‰æ–¹æ³•å› ä¾èµ–ç¨€ç–å…¨å±€å¥–åŠ±è€Œç¼ºä¹å¯¹ä¸­é—´æœç´¢è¿‡ç¨‹ç»†ç²’åº¦ç›‘ç£çš„é—®é¢˜ï¼Œé€šè¿‡å¼•å…¥åŸºäºä¿¡æ¯å¢ç›Šå’Œå†—ä½™æƒ©ç½šçš„tokençº§åˆ«æ­¥éª¤å¥–åŠ±æœºåˆ¶ï¼ˆStePPOï¼‰ï¼Œè§£å†³äº†å…¶åœ¨å¤æ‚å¤šè·³é—®ç­”ä¸­ç¼ºä¹ä¸­é—´æŸ¥è¯¢å’Œå¤šæ­¥æ£€ç´¢ç»†ç²’åº¦ç›‘ç£çš„é—®é¢˜ã€‚éœ€è¦åšæ•°æ®å¢å¼ºå¾—åˆ°Goldenè½¨è¿¹ [![[code]](https://img.shields.io/github/stars/Zillwang/StepSearch)](https://github.com/Zillwang/StepSearch)
- [2025.05] [[R1-Searcher++]](https://arxiv.org/abs/2505.17005) R1-Searcher++: Incentivizing the Dynamic Knowledge Acquisition of LLMs via Reinforcement Learning ä½œä¸ºR1-Searcherçš„å¢å¼ºç‰ˆï¼Œè§£å†³å¦‚ä½•æ›´å¥½åœ°åˆ©ç”¨å†…éƒ¨å’Œå¤–éƒ¨çŸ¥è¯†çš„é—®é¢˜ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µç­–ç•¥ï¼Œå¼•å…¥å†…éƒ¨çŸ¥è¯†åˆ©ç”¨å¥–åŠ±æœºåˆ¶å’Œè®°å¿†æœºåˆ¶ï¼Œå®ç°åŠ¨æ€çŸ¥è¯†è·å– [![[code]](https://img.shields.io/github/stars/RUCAIBox/R1-Searcher-plus)](https://github.com/RUCAIBox/R1-Searcher-plus)
- [2025.05] [[Search Wisely Î²-GRPO]](https://arxiv.org/abs/2505.17281) Search Wisely: Mitigating Sub-optimal Agentic Searches By Reducing Uncertainty è§£å†³ä»£ç†æœç´¢ä¸­å­˜åœ¨çš„ä¸ç¡®å®šæ€§å¯¼è‡´æ¬¡ä¼˜æœç´¢è¡Œä¸ºï¼ˆæœç´¢ä¸è¶³orå†—ä½™æœç´¢ï¼‰çš„é—®é¢˜ï¼Œé€šè¿‡å‡å°‘ä¸ç¡®å®šæ€§æ¥ç¼“è§£æ¬¡ä¼˜çš„ä»£ç†æœç´¢ï¼Œæé«˜æœç´¢æ•ˆç‡å’Œè´¨é‡ [![[code]](https://img.shields.io/github/stars/mianzhang/Search-R1)](https://github.com/mianzhang/Search-R1)
- [2025.05] [[LeTS]](https://arxiv.org/abs/2505.17447) LeTS: Learning to Think-and-Search via Process-and-Outcome Reward Hybridization è§£å†³äº†Search-R1/ReSearchç­‰ç»“æœç›‘ç£RLæ–¹æ³•å› å¿½ç•¥ä¸­é—´æ­¥éª¤è€Œå¯¼è‡´çš„å†—ä½™æœç´¢ä¸æ— å…³æœç´¢é—®é¢˜ï¼Œé€šè¿‡è®¾è®¡åŸºäºè§„åˆ™çš„è¿‡ç¨‹çº§å¥–åŠ±æ¨¡å—ï¼ˆåŒ…æ‹¬ æƒ©ç½šåŒä¸€è½¨è¿¹å†…é‡å¤æ£€ç´¢ç›¸åŒæ–‡æ¡£çš„è¡Œä¸º å’Œ åˆ©ç”¨ç»„å†…ä¼˜ç§€è½¨è¿¹æŒ‡å¯¼å¼±è½¨è¿¹ï¼Œè§£å†³æ— å…³æœç´¢é—®é¢˜ï¼‰å¹¶ç”¨è¿‡ç¨‹å¥–åŠ±åŠ¨æ€è°ƒæ•´ç»“æœå¥–åŠ±çš„ä¼˜åŠ¿å€¼å®ç°è¿‡ç¨‹-ç»“æœå¥–åŠ±æ··åˆ [![[code]](https://img.shields.io/github/stars/Cheungki/LeTS)](https://github.com/Cheungki/LeTS)
- [2025.05] [[EvolveSearch]](https://arxiv.org/abs/2505.22501) EvolveSearch: An Iterative Self-Evolving Search Agent è§£å†³å½“å‰æœç´¢ä»£ç†éœ€è¦å¤–éƒ¨äººå·¥æ ‡æ³¨æ¨ç†è½¨è¿¹çš„é—®é¢˜ï¼Œæå‡ºè¿­ä»£è‡ªè¿›åŒ–æ¡†æ¶ï¼ŒååŒç»“åˆRLä¸SFTï¼Œæ— éœ€å¤–éƒ¨äººå·¥æ ‡æ³¨å³å¯æå‡ç½‘ç»œæœç´¢èƒ½åŠ›ï¼Œå®ç°è‡ªæˆ‘è¿›åŒ–
- [2025.06] [[R-Search]](https://arxiv.org/abs/2506.04185) R-Search: Empowering LLM Reasoning with Search via Multi-Reward Reinforcement Learning é€šè¿‡å¼•å…¥å¤šé˜¶æ®µæ··åˆå¥–åŠ±æœºåˆ¶ï¼ˆç­”æ¡ˆè´¨é‡ã€è·¨æ¨¡å‹è¯æ®è´¨é‡ã€æ ¼å¼æ­£ç¡®æ€§ï¼‰å’Œè¯æ®æ•´åˆæ¨¡å—ï¼Œè§£å†³äº†Search-R1ä¸­æ£€ç´¢æ—¶æœºä¸çœŸå®éœ€æ±‚ä¸å¯¹é½ã€æ¨ç†-æœç´¢äº¤äº’æ·±åº¦å—é™çš„é—®é¢˜ï¼Œä½¿LLMèƒ½å¤ŸåŠ¨æ€å†³å®šä½•æ—¶æ£€ç´¢å¹¶ä»å…¨å±€è§†è§’æç‚¼å…³é”®è¯æ®ï¼Œä»è€Œä¼˜åŒ–æ•´ä¸ªæ¨ç†-æœç´¢äº¤äº’è½¨è¿¹ [![[code]](https://img.shields.io/github/stars/QingFei1/R-Search)](https://github.com/QingFei1/R-Search)
- [2025.08] [[Self-Search RL]](https://arxiv.org/abs/2508.10874) SSRL: Self-Search Reinforcement Learning ç ”ç©¶LLMä½œä¸ºRLä»»åŠ¡æ¨¡æ‹Ÿå™¨çš„æ½œåŠ›ï¼Œè®­ç»ƒLLMç›´æ¥ä½œä¸ºæœç´¢å¼•æ“ï¼Œå‡å°‘å¯¹å¤–éƒ¨æœç´¢å¼•æ“çš„æ˜‚è´µäº¤äº’ä¾èµ–ï¼Œé€šè¿‡ç»“æ„åŒ–æç¤ºå’Œé‡å¤é‡‡æ ·é‡åŒ–LLMçš„å†…åœ¨æœç´¢èƒ½åŠ›ï¼Œå¢å¼ºè‡ªæˆ‘æœç´¢èƒ½åŠ› [![[code]](https://img.shields.io/github/stars/TsinghuaC3I/SSRL)](https://github.com/TsinghuaC3I/SSRL)
- [2025.08] [[ASearcher]](https://arxiv.org/abs/2508.07976) Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL è§£å†³é•¿è§†é‡æœç´¢ä»»åŠ¡çš„æŒ‘æˆ˜ï¼Œé€šè¿‡å¤§è§„æ¨¡å¼‚æ­¥å¼ºåŒ–å­¦ä¹ è§£é”é•¿è§†é‡ä»£ç†æœç´¢èƒ½åŠ›ï¼Œæ”¯æŒè¶…è¿‡åè½®ä»¥ä¸Šçš„å¤æ‚æœç´¢äº¤äº’ [![[code]](https://img.shields.io/github/stars/inclusionAI/ASearcher)](https://github.com/inclusionAI/ASearcher)
- [2025.10] [[DeSA]](https://arxiv.org/abs/2510.04695) Beyond Outcome Reward: Decoupling Search and Answering Improves LLM Agents ç›®å‰Search-R1ä¸»è¦ä¾èµ–åŸºäºç»“æœçš„å¥–åŠ±ï¼Œè¿™éšå«äº†ä¸€ä¸ªå…³é”®å‡è®¾ï¼šä¼˜åŒ–æœ€ç»ˆç­”æ¡ˆä¼šè‡ªåŠ¨æ•™ä¼šæ™ºèƒ½ä½“è¿›è¡Œæœ‰æ•ˆæœç´¢ã€‚ä½œè€…è´¨ç–‘è¿™ä¸€å‡è®¾ï¼ŒæŒ‡å‡ºç»“æœå¥–åŠ±å­˜åœ¨ä»¥ä¸‹æ ¹æœ¬ç¼ºé™·ï¼šä¿¡ç”¨åˆ†é…é—®é¢˜ï¼šç»“æœå¥–åŠ±æä¾›çš„æ˜¯ç¨€ç–ã€å»¶è¿Ÿçš„åé¦ˆï¼Œæ— æ³•æœ‰æ•ˆæŒ‡å¯¼ä¸­é—´çš„æœç´¢è¡Œä¸º è¡Œä¸º-ç»“æœè„±èŠ‚ï¼šæ²¡æœ‰è¯æ®è¡¨æ˜å¥½çš„ç»“æœå¿…ç„¶æ¥è‡ªäºæœ‰æ•ˆçš„æœç´¢è¿‡ç¨‹ã€‚å¯¼è‡´ä¸æœç´¢ï¼Œé‡å¤æœç´¢ï¼Œæ— æ•ˆæœç´¢ã€‚ [![[code]](https://img.shields.io/github/stars/yiding-w/DeSA)](https://github.com/yiding-w/DeSA)
- [2025.10] [[HiPRAG]](https://arxiv.org/abs/2510.07794) HiPRAG: Hierarchical Process Rewards for Efficient Agentic Retrieval Augmented Generation é€šè¿‡åˆ†å±‚è¿‡ç¨‹å¥–åŠ±ä¼˜åŒ–RAGæ™ºèƒ½ä½“æœç´¢å†³ç­–ï¼Œå°†æ¨ç†è½¨è¿¹åˆ†è§£ä¸ºå¯è§£ææ­¥éª¤å¹¶å®æ—¶æ£€æµ‹å†—ä½™/ç¼ºå¤±æœç´¢ Î²-GRPOç»­ä½œ [![[code]](https://img.shields.io/github/stars/qualidea1217/HiPRAG)](https://github.com/qualidea1217/HiPRAG)
- [2025.10] [[QAgent]](https://arxiv.org/abs/2510.08383) QAgent: A modular Search Agent with Interactive Query Understanding è§£å†³ä¼ ç»ŸRAGéš¾ä»¥ç†è§£å¤æ‚æŸ¥è¯¢ã€RLè®­ç»ƒæœç´¢ä»£ç†æ³›åŒ–å’Œéƒ¨ç½²å›°éš¾çš„é—®é¢˜ï¼Œæå‡ºæ¨¡å—åŒ–æœç´¢ä»£ç†æ¡†æ¶ï¼Œé€šè¿‡äº¤äº’å¼æ¨ç†å’Œæ£€ç´¢ä¼˜åŒ–æŸ¥è¯¢ç†è§£ï¼Œå³æ’å³ç”¨äºå¤æ‚ç³»ç»Ÿ [![[code]](https://img.shields.io/github/stars/LivingFutureLab/QAgent)](https://github.com/LivingFutureLab/QAgent)
- [2025.10] [[InfoFlow]](https://arxiv.org/abs/2510.26575) InfoFlow: Reinforcing Search Agent via Reward Density Optimization è§£å†³æ·±åº¦æœç´¢åœºæ™¯ä¸­å¥–åŠ±å¯†åº¦ä½ã€æ¢ç´¢æˆæœ¬é«˜çš„é—®é¢˜ï¼Œæå‡ºå¥–åŠ±å¯†åº¦ä¼˜åŒ–æ¡†æ¶ï¼Œé€šè¿‡å­é—®é¢˜åˆ†è§£ã€å¤±è´¥å¼•å¯¼æç¤ºå’ŒåŒä»£ç†ç²¾ç‚¼ä¸‰æ–¹é¢æé«˜å¥–åŠ±å¯†åº¦å’Œè®­ç»ƒæ•ˆç‡
- [2025.10] [[Search Self-play]](https://arxiv.org/abs/2510.18821) Search Self-play: Pushing the Frontier of Agent Capability without Supervision è§£å†³æ— ç›‘ç£æƒ…å†µä¸‹å¦‚ä½•æå‡ä»£ç†èƒ½åŠ›çš„é—®é¢˜ï¼Œé€šè¿‡æœç´¢è‡ªæˆ‘åšå¼ˆå¼ºåŒ–å­¦ä¹ ï¼Œè®©LLMäº¤æ›¿æé—®å’Œè§£å†³æŒç»­è®­ç»ƒè‡ªæˆ‘è¿›åŒ–ï¼Œæ— éœ€ç›‘ç£å³å¯æ¨åŠ¨ä»£ç†èƒ½åŠ›è¾¹ç•Œï¼Œè§£å†³å½“å‰è®­ç»ƒAgentçš„RLæ–¹æ³•å¯¹æ•°æ®çš„ä¾èµ–é—®é¢˜ [![[code]](https://img.shields.io/github/stars/Alibaba-Quark/SSP)](https://github.com/Alibaba-Quark/SSP)
- [2025.10] [[E-GRPO]](https://arxiv.org/abs/2510.24694) Repurposing Synthetic Data for Fine-grained Search Agent Supervision è§£å†³GRPOæ–¹æ³•ç¼ºä¹ç»†ç²’åº¦ç›‘ç£ä¿¡å·çš„é—®é¢˜ï¼Œæå‡ºE-GRPOæ¡†æ¶ï¼Œåˆ©ç”¨åˆæˆæ•°æ®ä¸­çš„å®ä½“ä¿¡æ¯ä½œä¸ºç»†ç²’åº¦å¥–åŠ±ï¼Œè§£å†³"è¿‘å¤±"é—®é¢˜ï¼Œæå‡å¤æ‚æœç´¢ä»»åŠ¡æ€§èƒ½
- [2025.10] [[GlobalRAG]](https://arxiv.org/abs/2510.20548) GlobalRAG: Enhancing Global Reasoning in Multi-hop Question Answering via Reinforcement Learning è§£å†³å¤šè·³QAä¸­ç¼ºä¹å…¨å±€è§„åˆ’å’Œä¸å¿ å®æ‰§è¡Œçš„é—®é¢˜ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ å¢å¼ºå…¨å±€æ¨ç†ï¼Œåˆ†è§£é—®é¢˜ä¸ºå­ç›®æ ‡ï¼Œåè°ƒæ£€ç´¢ä¸æ¨ç†ï¼Œä»…ä½¿ç”¨8kè®­ç»ƒæ•°æ®å°±å®ç°æ˜¾è‘—æ€§èƒ½æå‡ã€‚éœ€è¦åšæ•°æ®å¢å¼ºå¾—åˆ°Goldenè½¨è¿¹ [![[code]](https://img.shields.io/github/stars/CarnegieBin/GlobalRAG)](https://github.com/CarnegieBin/GlobalRAG)
- [2025.12] [[RouteRAG]](https://arxiv.org/pdf/2512.09487) RouteRAG: Efficient Retrieval-Augmented Generation from Text and Graph via Reinforcement Learning è§£å†³RAGç¼ºä¹è‡ªé€‚åº”èƒ½åŠ›ï¼šå›¾ç»“æ„æˆ–æ··åˆæ£€ç´¢ç³»ç»Ÿä¾èµ–å›ºå®šæµç¨‹ï¼Œæ— æ³•åƒæ–‡æœ¬RAGé‚£æ ·é€šè¿‡å¼ºåŒ–å­¦ä¹ å®ç°å¤šè½®åŠ¨æ€æ£€ç´¢ï¼Œéš¾ä»¥åœ¨æ¨ç†è¿‡ç¨‹ä¸­æŒ‰éœ€è¡¥å……è¯æ®ï¼›æ£€ç´¢æ•ˆç‡é—®é¢˜ï¼šå›¾æ£€ç´¢è™½å¯¹å¤šè·³æ¨ç†è‡³å…³é‡è¦ï¼Œä½†è®¡ç®—æˆæœ¬è¿œé«˜äºæ–‡æœ¬æ£€ç´¢ï¼Œç°æœ‰æ–¹æ³•æ— æ³•æ ¹æ®æŸ¥è¯¢éœ€æ±‚çµæ´»é€‰æ‹©æ£€ç´¢æ–¹å¼ï¼Œå¯¼è‡´ä¸å¿…è¦çš„å¼€é”€ï¼›é€šè¿‡Search-R1çš„èŒƒå¼å®ç°ï¼Œä¸¤é˜¶æ®µRLè®­ç»ƒ[![[code]](https://img.shields.io/github/stars/YucanGuo/RouteRAG)](https://github.com/YucanGuo/RouteRAG)
